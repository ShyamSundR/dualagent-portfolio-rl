{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibMGdu5Cd7Qp",
        "outputId": "d58c2968-932d-4dd1-ef35-dc6a6f774e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gym in /home1/srajasek/.local/lib/python3.12/site-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from gym) (2.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /home1/srajasek/.local/lib/python3.12/site-packages (from gym) (0.0.8)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/apps/conda/envs/ood-jupyterlab-4.2/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuBvuZdHeCte",
        "outputId": "0249b802-2d1c-4435-840c-addf4e0bbbbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: stable_baselines3 in /home1/srajasek/.local/lib/python3.12/site-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /home1/srajasek/.local/lib/python3.12/site-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (72.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from matplotlib->stable_baselines3) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home1/srajasek/.local/lib/python3.12/site-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (2.1.5)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/apps/conda/envs/ood-jupyterlab-4.2/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUXgwNnadJJ-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import gym\n",
        "from gym import spaces\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwsMuoEndN0a"
      },
      "outputs": [],
      "source": [
        "# Create directories\n",
        "for directory in ['data', 'figures', 'models', 'results']:\n",
        "    os.makedirs(directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wazpf9l-dPZ2"
      },
      "outputs": [],
      "source": [
        "def efeatures(df):\n",
        "\n",
        "    print(\"Adding enhanced features...\")\n",
        "\n",
        "    # Get all unique tickers\n",
        "    assets = set()\n",
        "    for col in df.columns:\n",
        "        if '_close' in col:\n",
        "            ticker = col.split('_')[0]\n",
        "            assets.add(ticker)\n",
        "\n",
        "    print(f\"Processing features for {len(assets)} tickers\")\n",
        "\n",
        "    # Technical indicators\n",
        "    print(\"Calculating technical indicators...\")\n",
        "\n",
        "    # RSI (Relative Strength Index)\n",
        "    for ticker in assets:\n",
        "        if f'{ticker}_close' in df.columns:\n",
        "            print(f\"Calculating RSI for {ticker}\")\n",
        "            # Calculate RSI (14-day period)\n",
        "            delta = df[f'{ticker}_close'].diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "            avg_gain = gain.rolling(window=14).mean()\n",
        "            avg_loss = loss.rolling(window=14).mean()\n",
        "            rs = avg_gain / (avg_loss + 1e-10)\n",
        "            df[f'{ticker}_rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Add moving averages and trend indicators\n",
        "    print(\"Calculating trend features for all tickers...\")\n",
        "    for ticker in assets:\n",
        "        if f'{ticker}_close' in df.columns:\n",
        "            print(f\"Calculating moving averages for {ticker}\")\n",
        "            # moving averages\n",
        "            df[f'{ticker}_sma_20'] = df[f'{ticker}_close'].rolling(20).mean()\n",
        "            df[f'{ticker}_sma_50'] = df[f'{ticker}_close'].rolling(50).mean()\n",
        "\n",
        "            # Price relative to MA\n",
        "            df[f'{ticker}_rel_sma20'] = df[f'{ticker}_close'] / (df[f'{ticker}_sma_20'] + 1e-10)\n",
        "            df[f'{ticker}_rel_sma50'] = df[f'{ticker}_close'] / (df[f'{ticker}_sma_50'] + 1e-10)\n",
        "\n",
        "            # Golden/death cross indicator (1 for golden, -1 for death, 0 for neither)\n",
        "            df[f'{ticker}_cross'] = 0\n",
        "            golden_cross = (df[f'{ticker}_sma_20'] > df[f'{ticker}_sma_50']) & (df[f'{ticker}_sma_20'].shift(1) <= df[f'{ticker}_sma_50'].shift(1))\n",
        "            death_cross = (df[f'{ticker}_sma_20'] < df[f'{ticker}_sma_50']) & (df[f'{ticker}_sma_20'].shift(1) >= df[f'{ticker}_sma_50'].shift(1))\n",
        "            df.loc[golden_cross, f'{ticker}_cross'] = 1\n",
        "            df.loc[death_cross, f'{ticker}_cross'] = -1\n",
        "\n",
        "    # Cross-market correlation features\n",
        "    print(\"Calculating cross-market correlations...\")\n",
        "\n",
        "    # SPY correlations with crypto\n",
        "    df['spy_btc_corr'] = df['SPY_return_30d'].rolling(30).corr(df['BTC_return_30d'])\n",
        "    df['spy_eth_corr'] = df['SPY_return_30d'].rolling(30).corr(df['ETH_return_30d'])\n",
        "\n",
        "    # Crypto correlations\n",
        "    df['btc_eth_corr'] = df['BTC_return_30d'].rolling(30).corr(df['ETH_return_30d'])\n",
        "\n",
        "    # Calculate sector-level features\n",
        "    tech = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'INTC', 'CSCO', 'ADBE', 'CRM']\n",
        "    finance = ['JPM', 'BAC', 'GS', 'MS', 'BLK']\n",
        "    healthcare = ['UNH', 'JNJ', 'PFE', 'MRK', 'ABBV', 'LLY', 'ABT', 'TMO', 'DHR', 'BMY']\n",
        "\n",
        "    # Calculate sector returns\n",
        "    print(\"Calculating sector-level features...\")\n",
        "    for sectorname, sector in [\n",
        "        ('tech', tech),\n",
        "        ('finance', finance),\n",
        "        ('healthcare', healthcare\n",
        "    ]:\n",
        "        valid_tickers = [t for t in sector if f'{t}_return_30d' in df.columns]\n",
        "\n",
        "        if valid_tickers:\n",
        "            # average sector return\n",
        "            sector_returns = pd.DataFrame()\n",
        "            for ticker in valid_tickers:\n",
        "                sector_returns[ticker] = df[f'{ticker}_return_30d']\n",
        "\n",
        "            df[f'{sectorname}_return_30d'] = sector_returns.mean(axis=1)\n",
        "\n",
        "            # sector volatility\n",
        "            sector_vols = pd.DataFrame()\n",
        "            for ticker in valid_tickers:\n",
        "                sector_vols[ticker] = df[f'{ticker}_vol_10d']\n",
        "\n",
        "            df[f'{sectorname}_vol_10d'] = sector_vols.mean(axis=1)\n",
        "\n",
        "    # Market breadth indicators\n",
        "    print(\"Calculating market breadth indicators...\")\n",
        "\n",
        "    # Calculate percentage of stocks with positive returns\n",
        "    returncols = [col for col in df.columns if col.endswith('_return_30d')\n",
        "                  and not col.startswith('BTC_') and not col.startswith('ETH_')\n",
        "                  and not col in ['tech_return_30d', 'finance_return_30d', 'healthcare_return_30d']]\n",
        "\n",
        "    positive_returns = pd.DataFrame()\n",
        "    for col in returncols:\n",
        "        positive_returns[col] = (df[col] > 0).astype(int)\n",
        "\n",
        "    # Calculate market breadth\n",
        "    for window in [5, 10, 20]:\n",
        "        df[f'market_breadth_{window}d'] = positive_returns.rolling(window).mean().mean(axis=1)\n",
        "\n",
        "    # Volatility ratio features\n",
        "    print(\"Calculating volatility ratios...\")\n",
        "\n",
        "    df['crypto_equity_vol_ratio'] = (df['BTC_vol_10d'] + df['ETH_vol_10d']) / (2 * df['SPY_vol_10d'] + 1e-10)\n",
        "\n",
        "    # Volatility regime features\n",
        "    print(\"Detecting volatility regimes...\")\n",
        "\n",
        "\n",
        "    df['market_vol_regime'] = 0\n",
        "    rolling_vol_mean = df['SPY_vol_10d'].rolling(90).mean()\n",
        "    rolling_vol_std = df['SPY_vol_10d'].rolling(90).std()\n",
        "\n",
        "    high_vol = df['SPY_vol_10d'] > (rolling_vol_mean + rolling_vol_std)\n",
        "    low_vol = df['SPY_vol_10d'] < (rolling_vol_mean - rolling_vol_std)\n",
        "\n",
        "    df.loc[high_vol, 'market_vol_regime'] = 1\n",
        "    df.loc[low_vol, 'market_vol_regime'] = -1\n",
        "\n",
        "    # Check for NaN values\n",
        "    nan_counts = df.isna().sum()\n",
        "    print(f\"NaN values after feature engineering: {nan_counts[nan_counts > 0].sum()}\")\n",
        "\n",
        "\n",
        "    print(\"Handling NaN values...\")\n",
        "\n",
        "    # Forward fill first\n",
        "    df = df.ffill()\n",
        "\n",
        "    # Backward fill next\n",
        "    df = df.bfill()\n",
        "\n",
        "    # For any remaining NaNs, fill with zeros or median values\n",
        "    for col in df.columns:\n",
        "        if df[col].isna().any():\n",
        "            if 'return' in col or 'vol' in col:\n",
        "                df[col] = df[col].fillna(0)\n",
        "            elif 'rsi' in col:\n",
        "                df[col] = df[col].fillna(50)\n",
        "            else:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    nan_counts_after = df.isna().sum()\n",
        "    print(f\"NaN values after filling: {nan_counts_after[nan_counts_after > 0].sum()}\")\n",
        "\n",
        "    print(\"Feature engineering complete.\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SboRrF5dUE1"
      },
      "outputs": [],
      "source": [
        "def sfeatures(df, correlation_threshold=0.7, importance_threshold=0.01):\n",
        "\n",
        "    print(\"Performing feature selection...\")\n",
        "\n",
        "    feature_df = df.copy()\n",
        "\n",
        "    # Remove non-feature columns\n",
        "    non_feature_cols = ['is_weekend', 'regime_name']\n",
        "\n",
        "    for col in feature_df.columns:\n",
        "        if pd.api.types.is_datetime64_any_dtype(feature_df[col]) or pd.api.types.is_object_dtype(feature_df[col]):\n",
        "            if col not in non_feature_cols:\n",
        "                non_feature_cols.append(col)\n",
        "\n",
        "    feature_df = feature_df.drop(columns=non_feature_cols, errors='ignore')\n",
        "\n",
        "    numeric_df = feature_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    numeric_df = numeric_df.dropna(axis=1, how='all')\n",
        "\n",
        "    print(f\"Using {len(numeric_df.columns)} numeric features for selection\")\n",
        "\n",
        "    # feature selection\n",
        "    target_cols = ['SPY_return_30d', 'BTC_return_30d', 'ETH_return_30d']\n",
        "    valid_targets = [col for col in target_cols if col in numeric_df.columns]\n",
        "\n",
        "    featureimportance = pd.DataFrame(index=numeric_df.columns)\n",
        "\n",
        "    # Calculate correlation\n",
        "    for target in valid_targets:\n",
        "        correlations = numeric_df.corrwith(numeric_df[target]).abs()\n",
        "        featureimportance[f'corr_{target}'] = correlations\n",
        "\n",
        "    # average correlation\n",
        "    featureimportance['avg_correlation'] = featureimportance.mean(axis=1)\n",
        "\n",
        "    corr_matrix = numeric_df.corr().abs()\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "    high_corr_pairs = []\n",
        "    for col in upper_tri.columns:\n",
        "        correlated_cols = upper_tri.index[upper_tri[col] > correlation_threshold].tolist()\n",
        "        for corr_col in correlated_cols:\n",
        "            high_corr_pairs.append((col, corr_col))\n",
        "\n",
        "\n",
        "    redundantfeatures = []\n",
        "    for feat1, feat2 in high_corr_pairs:\n",
        "        if feat1 not in redundantfeatures and feat2 not in redundantfeatures:\n",
        "            if featureimportance.loc[feat1, 'avg_correlation'] > featureimportance.loc[feat2, 'avg_correlation']:\n",
        "                redundantfeatures.append(feat2)\n",
        "            else:\n",
        "                redundantfeatures.append(feat1)\n",
        "\n",
        "    # Select features with importance above threshold\n",
        "    importantfeatures = featureimportance[\n",
        "        featureimportance['avg_correlation'] > importance_threshold\n",
        "    ].index.tolist()\n",
        "\n",
        "    selectedfeatures = [feat for feat in importantfeatures if feat not in redundantfeatures]\n",
        "\n",
        "    # critical features\n",
        "    criticalfeatures = [\n",
        "        'market_regime', 'market_vol_regime',\n",
        "        'SPY_return_30d', 'BTC_return_30d', 'ETH_return_30d',\n",
        "        'SPY_vol_10d', 'BTC_vol_10d', 'ETH_vol_10d',\n",
        "        'spy_btc_corr', 'spy_eth_corr', 'btc_eth_corr',\n",
        "        'market_breadth_20d', 'crypto_equity_vol_ratio'\n",
        "    ]\n",
        "\n",
        "    for feature in criticalfeatures:\n",
        "        if feature in df.columns and feature not in selectedfeatures:\n",
        "            selectedfeatures.append(feature)\n",
        "\n",
        "    # price data\n",
        "    for ticker in df.columns:\n",
        "        if ticker.endswith('_close'):\n",
        "            if ticker not in selectedfeatures:\n",
        "                selectedfeatures.append(ticker)\n",
        "\n",
        "    print(f\"Selected {len(selectedfeatures)} features out of {len(feature_df.columns)}\")\n",
        "    return selectedfeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrnidY4kdY9X"
      },
      "outputs": [],
      "source": [
        "class MultiMarketPortfolioEnv(gym.Env):\n",
        "\n",
        "\n",
        "    def __init__(self, data, selected_features=None, window_size=30,\n",
        "                 train_period=(0, 1800), max_steps=252, transaction_cost=0.001,\n",
        "                 mode='train', agent_type='dual'):\n",
        "        super(MultiMarketPortfolioEnv, self).__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.selected_features = selected_features\n",
        "        self.window_size = window_size\n",
        "        self.train_start, self.train_end = train_period\n",
        "\n",
        "        # appropriate max_steps\n",
        "        train_window_size = self.train_end - self.train_start\n",
        "        if max_steps is None or max_steps > train_window_size:\n",
        "            self.max_steps = max(1, train_window_size // 2)\n",
        "        else:\n",
        "            self.max_steps = max_steps\n",
        "\n",
        "        if self.train_end - self.train_start - self.window_size <= 0:\n",
        "            # a minimal lookback\n",
        "            self.window_size = max(1, (self.train_end - self.train_start) // 5)\n",
        "            print(f\"Adjusted window_size to {self.window_size} to fit training period\")\n",
        "\n",
        "        if self.max_steps > (self.train_end - self.train_start - self.window_size):\n",
        "            self.max_steps = max(1, self.train_end - self.train_start - self.window_size)\n",
        "\n",
        "        print(f\"Using max_steps={self.max_steps} for training window {self.train_start}:{self.train_end}\")\n",
        "\n",
        "        self.transaction_cost = transaction_cost\n",
        "        self.mode = mode\n",
        "        self.agent_type = agent_type\n",
        "\n",
        "        self.assets = []\n",
        "        for col in data.columns:\n",
        "            if col.endswith('_close'):\n",
        "                ticker = col.split('_')[0]\n",
        "                self.assets.append(ticker)\n",
        "\n",
        "        self.n_assets = len(self.assets)\n",
        "        print(f\"Environment created with {self.n_assets} assets\")\n",
        "\n",
        "        # action space\n",
        "        self.action_space = spaces.Box(\n",
        "            low=0, high=1, shape=(self.n_assets,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        self.current_step = self.train_start + self.window_size\n",
        "        self.portfolio_value = 1.0\n",
        "        self.weights = np.ones(self.n_assets) / self.n_assets\n",
        "        self.prev_weights = self.weights.copy()\n",
        "        self.portfolio_values = [self.portfolio_value]\n",
        "        self.returns = []\n",
        "        self.sharpe_ratio = 0\n",
        "        self.max_drawdown = 0\n",
        "\n",
        "        if self.agent_type == 'strategic':\n",
        "            # For strategic agent\n",
        "            obs_dim = 5 + 3 + len(self.assets) + len(self.assets) + 3\n",
        "        elif self.agent_type == 'tactical':\n",
        "            # For tactical agent\n",
        "            obs_dim = len(self.assets) * 3 + 3 + len(self.assets) + len(self.assets)\n",
        "        else:\n",
        "            obs_dim = (5 + 3 + len(self.assets) + len(self.assets) + 3) + \\\n",
        "                     (len(self.assets) * 3 + 3 + len(self.assets) + len(self.assets))\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Now reset to initialize properly\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            low = self.train_start + self.window_size\n",
        "            high = self.train_end - self.max_steps\n",
        "\n",
        "            if low >= high:\n",
        "                self.current_step = self.train_start + self.window_size\n",
        "                print(f\"Warning: Invalid random range ({low} >= {high}). Using fixed start index: {self.current_step}\")\n",
        "            else:\n",
        "                self.current_step = np.random.randint(low, high)\n",
        "        else:\n",
        "            # beginning of test period\n",
        "            self.current_step = self.train_start + self.window_size\n",
        "\n",
        "        self.start_step = self.current_step\n",
        "        self.end_step = min(self.current_step + self.max_steps, self.train_end)\n",
        "\n",
        "        # Initialize portfolio\n",
        "        self.portfolio_value = 1.0\n",
        "        self.initial_portfolio_value = 1.0\n",
        "        self.weights = np.ones(self.n_assets) / self.n_assets\n",
        "        self.prev_weights = self.weights.copy()\n",
        "\n",
        "        # Track portfolio\n",
        "        self.portfolio_values = [self.portfolio_value]\n",
        "        self.returns = []\n",
        "        self.sharpe_ratio = 0\n",
        "        self.max_drawdown = 0\n",
        "\n",
        "        # initial state\n",
        "        state = self.get_state()\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_state(self):\n",
        "        if self.agent_type == 'strategic':\n",
        "            return self.get_strategic_state()\n",
        "        elif self.agent_type == 'tactical':\n",
        "            return self.get_tactical_state()\n",
        "        else:\n",
        "            strategic_state = self.get_strategic_state()\n",
        "            tactical_state = self.get_tactical_state()\n",
        "            return np.concatenate([strategic_state, tactical_state])\n",
        "\n",
        "    def get_strategic_state(self):\n",
        "        # Market regime features\n",
        "        regime = self.data.iloc[self.current_step]['market_regime']\n",
        "        vol_regime = self.data.iloc[self.current_step]['market_vol_regime'] if 'market_vol_regime' in self.data.columns else 0\n",
        "\n",
        "        # Market breadth indicator\n",
        "        market_breadth = self.data.iloc[self.current_step]['market_breadth_20d'] if 'market_breadth_20d' in self.data.columns else 0.5\n",
        "\n",
        "        # Cross-market correlations\n",
        "        spy_btc_corr = self.data.iloc[self.current_step]['spy_btc_corr'] if 'spy_btc_corr' in self.data.columns else 0\n",
        "        spy_eth_corr = self.data.iloc[self.current_step]['spy_eth_corr'] if 'spy_eth_corr' in self.data.columns else 0\n",
        "\n",
        "        # Sector returns\n",
        "        sector_returns = []\n",
        "        for sector in ['tech', 'finance', 'healthcare']:\n",
        "            if f'{sector}_return_30d' in self.data.columns:\n",
        "                sector_returns.append(self.data.iloc[self.current_step][f'{sector}_return_30d'])\n",
        "            else:\n",
        "                sector_returns.append(0)\n",
        "\n",
        "        # Asset returns\n",
        "        asset_returns = []\n",
        "        for asset in self.assets:\n",
        "            if f'{asset}_return_30d' in self.data.columns:\n",
        "                asset_returns.append(self.data.iloc[self.current_step][f'{asset}_return_30d'])\n",
        "            else:\n",
        "                asset_returns.append(0)\n",
        "\n",
        "        # Previous portfolio weights\n",
        "        prev_weights = self.prev_weights.copy()\n",
        "\n",
        "        # Current portfolio\n",
        "        if len(self.returns) > 0:\n",
        "            recent_return = self.returns[-1]\n",
        "            if len(self.returns) >= 30:\n",
        "                rolling_sharpe = self.sharpe_ratio\n",
        "            else:\n",
        "                rolling_sharpe = 0\n",
        "        else:\n",
        "            recent_return = 0\n",
        "            rolling_sharpe = 0\n",
        "\n",
        "        state = np.concatenate([\n",
        "            [regime, vol_regime, market_breadth, spy_btc_corr, spy_eth_corr],\n",
        "            sector_returns,\n",
        "            asset_returns,\n",
        "            prev_weights,\n",
        "            [recent_return, rolling_sharpe, self.max_drawdown]\n",
        "        ])\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_tactical_state(self):\n",
        "        # volatility\n",
        "        asset_vols = []\n",
        "        for asset in self.assets:\n",
        "            if f'{asset}_vol_10d' in self.data.columns:\n",
        "                asset_vols.append(self.data.iloc[self.current_step][f'{asset}_vol_10d'])\n",
        "            else:\n",
        "                asset_vols.append(0.01)\n",
        "\n",
        "        # RSI indicators\n",
        "        asset_rsis = []\n",
        "        for asset in self.assets:\n",
        "            if f'{asset}_rsi' in self.data.columns:\n",
        "                asset_rsis.append(self.data.iloc[self.current_step][f'{asset}_rsi'])\n",
        "            else:\n",
        "                asset_rsis.append(50)\n",
        "\n",
        "        # Trend indicators\n",
        "        trend_indicators = []\n",
        "        for asset in self.assets:\n",
        "            if f'{asset}_cross' in self.data.columns:\n",
        "                trend_indicators.append(self.data.iloc[self.current_step][f'{asset}_cross'])\n",
        "            else:\n",
        "                trend_indicators.append(0)\n",
        "\n",
        "        # Cross-asset volatility ratio\n",
        "        crypto_equity_ratio = self.data.iloc[self.current_step]['crypto_equity_vol_ratio'] if 'crypto_equity_vol_ratio' in self.data.columns else 1\n",
        "\n",
        "        # Recent regime\n",
        "        recent_regime_change = 0\n",
        "        if self.current_step > 5:\n",
        "            if (self.data.iloc[self.current_step]['market_regime'] !=\n",
        "                self.data.iloc[self.current_step-5]['market_regime']):\n",
        "                recent_regime_change = 1\n",
        "\n",
        "        # Weekend feature\n",
        "        is_weekend = 1 if self.data.iloc[self.current_step]['is_weekend'] else 0\n",
        "\n",
        "        # Previous portfolio weights\n",
        "        prev_weights = self.prev_weights.copy()\n",
        "\n",
        "        price_changes = []\n",
        "        for asset in self.assets:\n",
        "            if self.current_step > 0 and f'{asset}_close' in self.data.columns:\n",
        "                prev_price = self.data.iloc[self.current_step-1][f'{asset}_close']\n",
        "                curr_price = self.data.iloc[self.current_step][f'{asset}_close']\n",
        "                if prev_price > 0:\n",
        "                    change = curr_price / prev_price - 1\n",
        "                else:\n",
        "                    change = 0\n",
        "                price_changes.append(change)\n",
        "            else:\n",
        "                price_changes.append(0)\n",
        "\n",
        "        state = np.concatenate([\n",
        "            asset_vols,\n",
        "            asset_rsis,\n",
        "            trend_indicators,\n",
        "            [crypto_equity_ratio, recent_regime_change, is_weekend],\n",
        "            prev_weights,\n",
        "            price_changes\n",
        "        ])\n",
        "\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        # Normalize action\n",
        "        action = np.clip(action, 0, 1)\n",
        "        action_sum = np.sum(action)\n",
        "        if action_sum > 0:\n",
        "            action = action / action_sum\n",
        "        else:\n",
        "            action = np.ones(self.n_assets) / self.n_assets\n",
        "\n",
        "        # transaction costs\n",
        "        tc = np.sum(np.abs(action - self.prev_weights)) * self.transaction_cost\n",
        "\n",
        "        # current weights\n",
        "        self.prev_weights = action.copy()\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.end_step or self.current_step >= len(self.data) - 1\n",
        "\n",
        "        if done:\n",
        "            returns = np.zeros(self.n_assets)\n",
        "            portfolio_return = 0\n",
        "        else:\n",
        "            # asset returns for day\n",
        "            returns = np.zeros(self.n_assets)\n",
        "            for i, asset in enumerate(self.assets):\n",
        "                prev_price = self.data.iloc[self.current_step-1][f'{asset}_close']\n",
        "                curr_price = self.data.iloc[self.current_step][f'{asset}_close']\n",
        "                returns[i] = curr_price / prev_price - 1\n",
        "\n",
        "            # Update portfolio\n",
        "            portfolio_return = np.sum(action * returns) - tc\n",
        "            self.portfolio_value *= (1 + portfolio_return)\n",
        "\n",
        "        self.portfolio_values.append(self.portfolio_value)\n",
        "        self.returns.append(portfolio_return)\n",
        "\n",
        "        # rolling performance\n",
        "        if len(self.returns) >= 30:\n",
        "            recent_returns = np.array(self.returns[-30:])\n",
        "            self.sharpe_ratio = np.mean(recent_returns) / (np.std(recent_returns) + 1e-6) * np.sqrt(252)\n",
        "\n",
        "            peak = np.maximum.accumulate(self.portfolio_values)\n",
        "            drawdown = (peak - self.portfolio_values) / peak\n",
        "            self.max_drawdown = np.max(drawdown)\n",
        "\n",
        "        #  rewards\n",
        "        if self.agent_type == 'strategic':\n",
        "            # Strategic reward: Sharpe ratio\n",
        "            reward = self.sharpe_ratio\n",
        "        elif self.agent_type == 'tactical':\n",
        "            # Tactical reward\n",
        "            vol_scaling = 1.0 / (np.std(returns) + 1e-6)\n",
        "            reward = portfolio_return * vol_scaling\n",
        "        else:\n",
        "            # Dual - combined reward\n",
        "            strategic_reward = self.sharpe_ratio\n",
        "\n",
        "            vol_scaling = 1.0 / (np.std(returns) + 1e-6)\n",
        "            tactical_reward = portfolio_return * vol_scaling\n",
        "\n",
        "            reward = strategic_reward + tactical_reward\n",
        "\n",
        "        next_state = self.get_state() if not done else np.zeros(self.observation_space.shape[0])\n",
        "\n",
        "        info = {\n",
        "            'portfolio_value': self.portfolio_value,\n",
        "            'portfolio_return': portfolio_return,\n",
        "            'transaction_cost': tc,\n",
        "            'weights': action,\n",
        "            'sharpe_ratio': self.sharpe_ratio,\n",
        "            'max_drawdown': self.max_drawdown\n",
        "        }\n",
        "\n",
        "        return next_state, reward, done, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqCNthHycjm1"
      },
      "outputs": [],
      "source": [
        "from gym import Wrapper, spaces\n",
        "\n",
        "class DiscreteActionWrapper(Wrapper):\n",
        "\n",
        "    def __init__(self, env, actions):\n",
        "        super(DiscreteActionWrapper, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.actions = actions\n",
        "\n",
        "        # Override the action space to be discrete\n",
        "        self.action_space = spaces.Discrete(len(actions))\n",
        "\n",
        "        # Store reference to assets\n",
        "        self.assets = env.assets\n",
        "        self.n_assets = len(env.assets)\n",
        "\n",
        "        # Store reference to the current weights\n",
        "        self.current_weights = np.ones(self.n_assets) / self.n_assets\n",
        "\n",
        "    def step(self, action):\n",
        "        # Convert discrete action to portfolio weights\n",
        "        continuous_action = self.convertaction(action)\n",
        "\n",
        "        # Call the original environment's step with the continuous action\n",
        "        obs, reward, done, info = self.env.step(continuous_action)\n",
        "\n",
        "        # Update current weights\n",
        "        if 'weights' in info:\n",
        "            self.current_weights = info['weights']\n",
        "\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.env.reset()\n",
        "        self.current_weights = np.ones(self.n_assets) / self.n_assets\n",
        "        return obs\n",
        "\n",
        "    def convertaction(self, action_idx):\n",
        "        # Get base weights from current environment\n",
        "        base_weights = self.current_weights.copy()\n",
        "\n",
        "        # If HOLD action, return base weights unchanged\n",
        "        if action_idx == 0 or action_idx >= len(self.actions):\n",
        "            return base_weights\n",
        "\n",
        "        # Get the action details\n",
        "        action = self.actions[action_idx]\n",
        "        new_weights = base_weights.copy()\n",
        "\n",
        "        # Identify crypto and equity indices\n",
        "        crypto_indices = [i for i, a in enumerate(self.assets) if a in ['BTC', 'ETH']]\n",
        "        equity_indices = [i for i, a in enumerate(self.assets) if a not in ['BTC', 'ETH']]\n",
        "\n",
        "        # Apply the tactical action\n",
        "        if action[\"type\"] == \"equity_increase\":\n",
        "            # Implementation as in your original code\n",
        "            crypto_total = sum(new_weights[i] for i in crypto_indices)\n",
        "            reduction = min(action[\"value\"], crypto_total)\n",
        "\n",
        "            # Reduce crypto weights\n",
        "            for i in crypto_indices:\n",
        "                if crypto_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / crypto_total)\n",
        "\n",
        "            # Increase equity weights\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] += reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "        elif action[\"type\"] == \"equity_decrease\":\n",
        "            # Implementation as in your original code\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            reduction = min(action[\"value\"], equity_total)\n",
        "\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "            for i in crypto_indices:\n",
        "                new_weights[i] += reduction / len(crypto_indices)\n",
        "\n",
        "        elif action[\"type\"] == \"crypto_increase\":\n",
        "            # Implementation as in your original code\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            reduction = min(action[\"value\"], equity_total)\n",
        "\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "            for i in crypto_indices:\n",
        "                new_weights[i] += reduction / len(crypto_indices)\n",
        "\n",
        "        elif action[\"type\"] == \"crypto_decrease\":\n",
        "            # Implementation as in your original code\n",
        "            crypto_total = sum(new_weights[i] for i in crypto_indices)\n",
        "            reduction = min(action[\"value\"], crypto_total)\n",
        "\n",
        "            for i in crypto_indices:\n",
        "                if crypto_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / crypto_total)\n",
        "\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] += reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "        # Ensure weights sum to 1\n",
        "        new_weights = np.clip(new_weights, 0, 1)\n",
        "        weight_sum = np.sum(new_weights)\n",
        "        if weight_sum > 0:\n",
        "            new_weights = new_weights / weight_sum\n",
        "\n",
        "        return new_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE_G29V7db6H"
      },
      "outputs": [],
      "source": [
        "class StrategicAgent:\n",
        "\n",
        "    def __init__(self, env, learning_rate=3e-4, use_tensorboard=False):\n",
        "        # Define network architecture\n",
        "        policy_kwargs = dict(\n",
        "            net_arch=[dict(pi=[128, 128, 64], vf=[128, 128, 64])],\n",
        "            activation_fn=nn.ReLU\n",
        "        )\n",
        "\n",
        "        # Set tensorboard log path (None if not using)\n",
        "        tensorboard_log = \"./tensorboard/strategic_agent/\" if use_tensorboard else None\n",
        "\n",
        "        # Create PPO agent\n",
        "        self.model = PPO(\n",
        "            \"MlpPolicy\",\n",
        "            env,\n",
        "            device=\"cuda\",\n",
        "            verbose=1,\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            learning_rate=learning_rate,\n",
        "            n_steps=2048,\n",
        "            batch_size=64,\n",
        "            gamma=0.99,\n",
        "            ent_coef=0.01,\n",
        "            clip_range=0.2,\n",
        "            tensorboard_log=tensorboard_log\n",
        "        )\n",
        "\n",
        "    def train(self, total_timesteps):\n",
        "        print(\"Training strategic agent...\")\n",
        "        self.model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    def predict(self, state, deterministic=False):\n",
        "        action, _ = self.model.predict(state, deterministic=deterministic)\n",
        "        return action\n",
        "\n",
        "    def save(self, path):\n",
        "        self.model.save(path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.model = PPO.load(path)\n",
        "\n",
        "\n",
        "class TacticalAgent:\n",
        "\n",
        "\n",
        "    def __init__(self, env, n_discrete_actions=5, learning_rate=1e-4):\n",
        "        self.env = env\n",
        "        self.n_assets = len(env.assets)\n",
        "\n",
        "        # Define discrete actions\n",
        "        self.actions = self.discreteactions()\n",
        "        self.n_discrete_actions = len(self.actions)\n",
        "\n",
        "        # Create a wrapper for discrete actions\n",
        "        self.wrapped_env = self.discrete_wrapper(env)\n",
        "\n",
        "        # Define network architecture\n",
        "        policy_kwargs = dict(\n",
        "            net_arch=[128, 128, 64],\n",
        "            activation_fn=nn.ReLU\n",
        "        )\n",
        "\n",
        "        # Create DQN agent\n",
        "        self.model = DQN(\n",
        "            \"MlpPolicy\",\n",
        "            self.wrapped_env,\n",
        "            device=\"cuda\",\n",
        "            verbose=1,\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            learning_rate=learning_rate,\n",
        "            buffer_size=100000,\n",
        "            learning_starts=1000,\n",
        "            batch_size=32,\n",
        "            gamma=0.95,\n",
        "            exploration_fraction=0.2,\n",
        "            exploration_final_eps=0.05,\n",
        "            tensorboard_log=None\n",
        "        )\n",
        "\n",
        "    def discrete_wrapper(self, env):\n",
        "        return DiscreteActionWrapper(env, self.actions)\n",
        "\n",
        "    def discreteactions(self):\n",
        "        actions = {\n",
        "            0: {\"name\": \"HOLD\", \"modify\": False},\n",
        "            1: {\"name\": \"EQUITY+\", \"type\": \"equity_increase\", \"value\": 0.1},\n",
        "            2: {\"name\": \"EQUITY-\", \"type\": \"equity_decrease\", \"value\": 0.1},\n",
        "            3: {\"name\": \"CRYPTO+\", \"type\": \"crypto_increase\", \"value\": 0.05},\n",
        "            4: {\"name\": \"CRYPTO-\", \"type\": \"crypto_decrease\", \"value\": 0.05}\n",
        "        }\n",
        "        return actions\n",
        "\n",
        "    def train(self, total_timesteps):\n",
        "        print(\"Training tactical agent (DQN)...\")\n",
        "        self.model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    def predict(self, state, base_weights=None, deterministic=False):\n",
        "\n",
        "        if base_weights is None:\n",
        "            base_weights = np.ones(self.n_assets) / self.n_assets\n",
        "\n",
        "        # Get discrete action from model\n",
        "        action, _ = self.model.predict(state, deterministic=deterministic)\n",
        "\n",
        "        # Convert discrete action to weight adjustments\n",
        "        modified_weights = self.aptactical_action(action, base_weights)\n",
        "\n",
        "        return modified_weights\n",
        "\n",
        "    def aptactical_action(self, action_idx, base_weights):\n",
        "        # If HOLD action, return base weights unchanged\n",
        "        if action_idx == 0:\n",
        "            return base_weights\n",
        "\n",
        "        # Get the action details\n",
        "        action_idx = int(action_idx)  # Fix unhashable numpy int\n",
        "        action = self.actions[action_idx]\n",
        "\n",
        "        new_weights = base_weights.copy()\n",
        "\n",
        "        # Identify crypto and equity indices\n",
        "        assets = self.env.assets\n",
        "        crypto_indices = [i for i, a in enumerate(assets) if a in ['BTC', 'ETH']]\n",
        "        equity_indices = [i for i, a in enumerate(assets) if a not in ['BTC', 'ETH']]\n",
        "\n",
        "        # Apply the tactical action\n",
        "        if action[\"type\"] == \"equity_increase\":\n",
        "            # Increase equity allocation by reducing crypto\n",
        "            crypto_total = sum(new_weights[i] for i in crypto_indices)\n",
        "            reduction = min(action[\"value\"], crypto_total)\n",
        "\n",
        "            # Reduce crypto weights\n",
        "            for i in crypto_indices:\n",
        "                if crypto_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / crypto_total)\n",
        "\n",
        "            # Increase equity weights\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] += reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "        elif action[\"type\"] == \"equity_decrease\":\n",
        "            # Decrease equity allocation by increasing crypto\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            reduction = min(action[\"value\"], equity_total)\n",
        "\n",
        "            # Reduce equity weights proportionally\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "            # Increase crypto weights proportionally\n",
        "            for i in crypto_indices:\n",
        "                new_weights[i] += reduction / len(crypto_indices)\n",
        "\n",
        "        elif action[\"type\"] == \"crypto_increase\":\n",
        "            # Increase crypto allocation by reducing equity\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            reduction = min(action[\"value\"], equity_total)\n",
        "\n",
        "            # Reduce equity weights\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "            # Increase crypto weights\n",
        "            for i in crypto_indices:\n",
        "                new_weights[i] += reduction / len(crypto_indices)\n",
        "\n",
        "        elif action[\"type\"] == \"crypto_decrease\":\n",
        "            # Decrease crypto allocation by increasing equity\n",
        "            crypto_total = sum(new_weights[i] for i in crypto_indices)\n",
        "            reduction = min(action[\"value\"], crypto_total)\n",
        "\n",
        "            # Reduce crypto weights\n",
        "            for i in crypto_indices:\n",
        "                if crypto_total > 0:\n",
        "                    new_weights[i] -= reduction * (new_weights[i] / crypto_total)\n",
        "\n",
        "            # Increase equity weights\n",
        "            equity_total = sum(new_weights[i] for i in equity_indices)\n",
        "            for i in equity_indices:\n",
        "                if equity_total > 0:\n",
        "                    new_weights[i] += reduction * (new_weights[i] / equity_total)\n",
        "\n",
        "        # Ensure weights sum to 1\n",
        "        new_weights = np.clip(new_weights, 0, 1)\n",
        "        weight_sum = np.sum(new_weights)\n",
        "        if weight_sum > 0:\n",
        "            new_weights = new_weights / weight_sum\n",
        "\n",
        "        return new_weights\n",
        "\n",
        "    def save(self, path):\n",
        "        self.model.save(path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.model = PPO.load(path)\n",
        "\n",
        "\n",
        "class DualAgentSystem:\n",
        "\n",
        "\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.assets = env.assets\n",
        "        self.n_assets = len(env.assets)\n",
        "\n",
        "        # Create strategic and tactical environments\n",
        "        strategic_env = MultiMarketPortfolioEnv(\n",
        "            env.data,\n",
        "            selected_features=env.selected_features,\n",
        "            window_size=env.window_size,\n",
        "            train_period=(env.train_start, env.train_end),\n",
        "            max_steps=env.max_steps,\n",
        "            transaction_cost=env.transaction_cost,\n",
        "            mode=env.mode,\n",
        "            agent_type='strategic'\n",
        "        )\n",
        "\n",
        "        tactical_env = MultiMarketPortfolioEnv(\n",
        "            env.data,\n",
        "            selected_features=env.selected_features,\n",
        "            window_size=env.window_size,\n",
        "            train_period=(env.train_start, env.train_end),\n",
        "            max_steps=env.max_steps,\n",
        "            transaction_cost=env.transaction_cost,\n",
        "            mode=env.mode,\n",
        "            agent_type='tactical'\n",
        "        )\n",
        "\n",
        "\n",
        "        self.strategic_agent = StrategicAgent(strategic_env)\n",
        "        # DQN-based tactical agent\n",
        "        self.tactical_agent = TacticalAgent(tactical_env)\n",
        "\n",
        "        # Initialize auction mechanism\n",
        "        self.auction_alpha = 0.5\n",
        "\n",
        "        # For tracking\n",
        "        self.strategic_actions = []\n",
        "        self.tactical_actions = []\n",
        "        self.combined_actions = []\n",
        "        self.alpha_history = []\n",
        "\n",
        "    def train(self, total_timesteps, train_strategic=True, train_tactical=True):\n",
        "        if train_strategic:\n",
        "            self.strategic_agent.train(total_timesteps=total_timesteps)\n",
        "\n",
        "        if train_tactical:\n",
        "            self.tactical_agent.train(total_timesteps=total_timesteps)\n",
        "\n",
        "    def differentiable_auction(self, strategic_value, tactical_value, epsilon=1e-6):\n",
        "        # Normalize values\n",
        "        total_value = abs(strategic_value) + abs(tactical_value) + epsilon\n",
        "        norm_strategic = abs(strategic_value) / total_value\n",
        "        norm_tactical = abs(tactical_value) / total_value\n",
        "\n",
        "        # Nash bargaining solution\n",
        "        alpha = norm_strategic / (norm_strategic + norm_tactical)\n",
        "\n",
        "        # Bound between 0.2 and 0.8 to prevent extreme allocations\n",
        "        alpha = max(0.2, min(0.8, alpha))\n",
        "\n",
        "        return alpha\n",
        "\n",
        "    def predict(self, state, deterministic=False):\n",
        "        # Split state each agent\n",
        "        strategic_state_dim = self.strategic_agent.model.observation_space.shape[0]\n",
        "        strategic_state = state[:strategic_state_dim]\n",
        "        tactical_state = state[strategic_state_dim:]\n",
        "\n",
        "        # actions from each agent\n",
        "        strategic_action = self.strategic_agent.predict(strategic_state, deterministic)\n",
        "        tactical_action = self.tactical_agent.predict(tactical_state, strategic_action, deterministic)\n",
        "\n",
        "        # Get value estimates for auction\n",
        "        strategic_value = self.strategic_agent.model.policy.evaluate_actions(\n",
        "            torch.tensor(strategic_state, dtype=torch.float32, device=self.strategic_agent.model.device).reshape(1, -1),\n",
        "            torch.tensor(strategic_action, dtype=torch.float32, device=self.strategic_agent.model.device).reshape(1, -1)\n",
        "        )[0].item()\n",
        "\n",
        "        tactical_value = self.tactical_agent.model.q_net(\n",
        "            torch.tensor(tactical_state, dtype=torch.float32, device=self.tactical_agent.model.device).reshape(1, -1)\n",
        "        ).max(dim=1)[0].item()\n",
        "\n",
        "\n",
        "        # risk budget allocation - differentiable auction\n",
        "        self.auction_alpha = self.differentiable_auction(strategic_value, tactical_value)\n",
        "\n",
        "        # Combine actions\n",
        "        combined_action = (\n",
        "            self.auction_alpha * strategic_action +\n",
        "            (1 - self.auction_alpha) * tactical_action\n",
        "        )\n",
        "\n",
        "        # Normalize\n",
        "        combined_action = np.clip(combined_action, 0, 1)\n",
        "        action_sum = np.sum(combined_action)\n",
        "        if action_sum > 0:\n",
        "            combined_action = combined_action / action_sum\n",
        "\n",
        "        # Track actions\n",
        "        self.strategic_actions.append(strategic_action)\n",
        "        self.tactical_actions.append(tactical_action)\n",
        "        self.combined_actions.append(combined_action)\n",
        "        self.alpha_history.append(self.auction_alpha)\n",
        "\n",
        "        return combined_action, self.auction_alpha\n",
        "\n",
        "    def save(self, path_prefix):\n",
        "        self.strategic_agent.save(f\"{path_prefix}_strategic\")\n",
        "        self.tactical_agent.save(f\"{path_prefix}_tactical\")\n",
        "\n",
        "    def load(self, path_prefix):\n",
        "        self.strategic_agent.load(f\"{path_prefix}_strategic\")\n",
        "        self.tactical_agent.load(f\"{path_prefix}_tactical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SXIvgBpHGS0"
      },
      "outputs": [],
      "source": [
        "def strategic_backtest(data, idx, assets):\n",
        "    # Market regime features\n",
        "    regime = data.iloc[idx]['market_regime']\n",
        "    vol_regime = data.iloc[idx]['market_vol_regime'] if 'market_vol_regime' in data.columns else 0\n",
        "\n",
        "    # Market breadth indicator\n",
        "    market_breadth = data.iloc[idx]['market_breadth_20d'] if 'market_breadth_20d' in data.columns else 0.5\n",
        "\n",
        "    # Cross-market correlations\n",
        "    spy_btc_corr = data.iloc[idx]['spy_btc_corr'] if 'spy_btc_corr' in data.columns else 0\n",
        "    spy_eth_corr = data.iloc[idx]['spy_eth_corr'] if 'spy_eth_corr' in data.columns else 0\n",
        "\n",
        "    # Sector returns\n",
        "    sector_returns = []\n",
        "    for sector in ['tech', 'finance', 'healthcare']:\n",
        "        if f'{sector}_return_30d' in data.columns:\n",
        "            sector_returns.append(data.iloc[idx][f'{sector}_return_30d'])\n",
        "        else:\n",
        "            sector_returns.append(0)\n",
        "\n",
        "    # Asset returns (30-day rolling)\n",
        "    asset_returns = []\n",
        "    for asset in assets:\n",
        "        if f'{asset}_return_30d' in data.columns:\n",
        "            asset_returns.append(data.iloc[idx][f'{asset}_return_30d'])\n",
        "        else:\n",
        "            asset_returns.append(0)\n",
        "\n",
        "    # Previous portfolio weights\n",
        "    prev_weights = np.ones(len(assets)) / len(assets)\n",
        "\n",
        "    # Current portfolio metrics\n",
        "    recent_return = 0\n",
        "    rolling_sharpe = 0\n",
        "    max_drawdown = 0\n",
        "\n",
        "    # state representation\n",
        "    state = np.concatenate([\n",
        "        [regime, vol_regime, market_breadth, spy_btc_corr, spy_eth_corr],\n",
        "        sector_returns,\n",
        "        asset_returns,\n",
        "        prev_weights,\n",
        "        [recent_return, rolling_sharpe, max_drawdown]\n",
        "    ])\n",
        "\n",
        "    return state\n",
        "\n",
        "def tactical_backtest(data, idx, assets):\n",
        "    # Get volatility for all assets\n",
        "    asset_vols = []\n",
        "    for asset in assets:\n",
        "        if f'{asset}_vol_10d' in data.columns:\n",
        "            asset_vols.append(data.iloc[idx][f'{asset}_vol_10d'])\n",
        "        else:\n",
        "            asset_vols.append(0.01)\n",
        "\n",
        "    # RSI indicators for all assets\n",
        "    asset_rsis = []\n",
        "    for asset in assets:\n",
        "        if f'{asset}_rsi' in data.columns:\n",
        "            asset_rsis.append(data.iloc[idx][f'{asset}_rsi'])\n",
        "        else:\n",
        "            asset_rsis.append(50)\n",
        "\n",
        "    # Trend indicators\n",
        "    trend_indicators = []\n",
        "    for asset in assets:\n",
        "        if f'{asset}_cross' in data.columns:\n",
        "            trend_indicators.append(data.iloc[idx][f'{asset}_cross'])\n",
        "        else:\n",
        "            trend_indicators.append(0)\n",
        "\n",
        "    # Cross-asset volatility ratio\n",
        "    crypto_equity_ratio = data.iloc[idx]['crypto_equity_vol_ratio'] if 'crypto_equity_vol_ratio' in data.columns else 1\n",
        "\n",
        "    # Recent market regime changes\n",
        "    recent_regime_change = 0\n",
        "    if idx > 5:\n",
        "        if (data.iloc[idx]['market_regime'] !=\n",
        "            data.iloc[idx-5]['market_regime']):\n",
        "            recent_regime_change = 1\n",
        "\n",
        "    # Weekend feature\n",
        "    is_weekend = 1 if data.iloc[idx]['is_weekend'] else 0\n",
        "\n",
        "    # Previous portfolio weights\n",
        "    prev_weights = np.ones(len(assets)) / len(assets)\n",
        "\n",
        "    # Daily price changes\n",
        "    price_changes = []\n",
        "    for asset in assets:\n",
        "        if idx > 0 and f'{asset}_close' in data.columns:\n",
        "            prev_price = data.iloc[idx-1][f'{asset}_close']\n",
        "            curr_price = data.iloc[idx][f'{asset}_close']\n",
        "            if prev_price > 0:\n",
        "                change = curr_price / prev_price - 1\n",
        "            else:\n",
        "                change = 0\n",
        "            price_changes.append(change)\n",
        "        else:\n",
        "            price_changes.append(0)\n",
        "\n",
        "\n",
        "    state = np.concatenate([\n",
        "        asset_vols,\n",
        "        asset_rsis,\n",
        "        trend_indicators,\n",
        "        [crypto_equity_ratio, recent_regime_change, is_weekend],\n",
        "        prev_weights,\n",
        "        price_changes\n",
        "    ])\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NU64miTdezy"
      },
      "outputs": [],
      "source": [
        "def backtestportfolio(model, data, start_idx, end_idx, transaction_cost=0.001):\n",
        "    print(f\"Backtesting from index {start_idx} to {end_idx}\")\n",
        "\n",
        "    # Initialize portfolio\n",
        "    portfolio_value = 1.0\n",
        "    portfolio_values = [portfolio_value]\n",
        "\n",
        "    # Extract assets\n",
        "    assets = []\n",
        "    for col in data.columns:\n",
        "        if col.endswith('_close'):\n",
        "            ticker = col.split('_')[0]\n",
        "            assets.append(ticker)\n",
        "\n",
        "    # Initialize weights\n",
        "    weights = np.ones(len(assets)) / len(assets)\n",
        "    weights_history = [weights.copy()]\n",
        "    returns_history = []\n",
        "    alpha_history = []\n",
        "\n",
        "    # Run backtest\n",
        "    for i in range(start_idx, end_idx - 1):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Backtesting step {i}/{end_idx-1}\")\n",
        "\n",
        "        # Prepare state\n",
        "        try:\n",
        "            if hasattr(model, 'predict') and callable(getattr(model, 'predict')):\n",
        "                # For RL models\n",
        "                if hasattr(model, 'strategic_agent') and hasattr(model, 'tactical_agent'):\n",
        "                    # For dual-agent system\n",
        "                    strategic_state = strategic_backtest(data, i, assets)\n",
        "                    tactical_state = tactical_backtest(data, i, assets)\n",
        "                    state = np.concatenate([strategic_state, tactical_state])\n",
        "                elif hasattr(model, 'model'):\n",
        "                    # Determine if strategic or tactical\n",
        "                    if model.__class__.__name__ == 'StrategicAgent':\n",
        "                        state = strategic_backtest(data, i, assets)\n",
        "                    else:\n",
        "                        state = tactical_backtest(data, i, assets)\n",
        "                else:\n",
        "                    # Use default state\n",
        "                    print(\"Warning: Unknown model type, using generic state\")\n",
        "                    state = np.ones(318)\n",
        "\n",
        "                # Get action\n",
        "                action_result = model.predict(state, deterministic=True)\n",
        "                if isinstance(action_result, tuple) and len(action_result) == 2:\n",
        "                    action, alpha = action_result\n",
        "                    alpha_history.append(float(alpha))\n",
        "                else:\n",
        "                    action = action_result\n",
        "                    alpha_history.append(0.5)\n",
        "            else:\n",
        "                # For baseline models\n",
        "                action = model(data, i, assets, weights)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {e}\")\n",
        "            action = weights\n",
        "            alpha_history.append(0.5)\n",
        "\n",
        "        # Ensure action is a proper numpy array\n",
        "        action = np.asarray(action, dtype=np.float32)\n",
        "        if action.shape != weights.shape:\n",
        "            print(f\"Warning: Action shape {action.shape} doesn't match weights shape {weights.shape}\")\n",
        "            action = weights\n",
        "\n",
        "        # Calculate transaction costs\n",
        "        tc = np.sum(np.abs(action - weights)) * transaction_cost\n",
        "\n",
        "        # Update weights\n",
        "        weights = action.copy()\n",
        "        weights_history.append(weights.copy())\n",
        "\n",
        "        # Get asset returns for the next day\n",
        "        next_day_returns = np.zeros(len(assets))\n",
        "        for j, asset in enumerate(assets):\n",
        "            prev_price = data.iloc[i][f'{asset}_close']\n",
        "            curr_price = data.iloc[i+1][f'{asset}_close']\n",
        "            next_day_returns[j] = curr_price / prev_price - 1\n",
        "\n",
        "        # Update portfolio value\n",
        "        portfolio_return = np.sum(weights * next_day_returns) - tc\n",
        "        returns_history.append(float(portfolio_return))\n",
        "        portfolio_value *= (1 + portfolio_return)\n",
        "        portfolio_values.append(float(portfolio_value))\n",
        "\n",
        "    portfolio_values = np.array(portfolio_values, dtype=np.float64)\n",
        "    returns_array = np.array(returns_history, dtype=np.float64)\n",
        "\n",
        "\n",
        "    if alpha_history:\n",
        "        alpha_history = np.array(alpha_history, dtype=np.float64)\n",
        "\n",
        "\n",
        "    # Annualized return\n",
        "    total_return = portfolio_values[-1] / portfolio_values[0] - 1\n",
        "    days = len(returns_history)\n",
        "    annualized_return = (1 + total_return) ** (252 / days) - 1\n",
        "\n",
        "    # Sharpe ratio\n",
        "    sharpe_ratio = np.mean(returns_array) / np.std(returns_array) * np.sqrt(252)\n",
        "\n",
        "    # Maximum drawdown\n",
        "    peak = np.maximum.accumulate(portfolio_values)\n",
        "    drawdown = (peak - portfolio_values) / peak\n",
        "    max_drawdown = np.max(drawdown)\n",
        "\n",
        "    # Sortino ratio\n",
        "    negative_returns = returns_array[returns_array < 0]\n",
        "    sortino_ratio = np.mean(returns_array) / (np.std(negative_returns) if len(negative_returns) > 0 else 1e-6) * np.sqrt(252)\n",
        "\n",
        "    # Calmar ratio\n",
        "    calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else np.inf\n",
        "\n",
        "    # Average turnover\n",
        "    try:\n",
        "        # list turnover values\n",
        "        turnover_values = []\n",
        "        for i in range(len(weights_history)-1):\n",
        "            turnover = np.sum(np.abs(weights_history[i+1] - weights_history[i])) / 2\n",
        "            turnover_values.append(turnover)\n",
        "\n",
        "        # average turnover\n",
        "        if len(weights_history) >= 2:\n",
        "            turnovers = [\n",
        "                np.sum(np.abs(weights_history[i] - weights_history[i-1])) / 2\n",
        "                for i in range(1, len(weights_history))\n",
        "            ]\n",
        "            avg_turnover = np.mean(turnovers)\n",
        "        else:\n",
        "            avg_turnover = 0\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating turnover: {e}\")\n",
        "        avg_turnover = 0\n",
        "\n",
        "    # average strategic allocation\n",
        "    avg_strategic_allocation = np.mean(alpha_history) if len(alpha_history) > 0 else None\n",
        "\n",
        "    metrics = {\n",
        "        \"total_return\": float(total_return),\n",
        "        \"annualized_return\": float(annualized_return),\n",
        "        \"sharpe_ratio\": float(sharpe_ratio),\n",
        "        \"sortino_ratio\": float(sortino_ratio),\n",
        "        \"max_drawdown\": float(max_drawdown),\n",
        "        \"calmar_ratio\": float(calmar_ratio),\n",
        "        \"avg_turnover\": float(avg_turnover),\n",
        "        \"avg_strategic_allocation\": float(avg_strategic_allocation) if avg_strategic_allocation is not None else None\n",
        "    }\n",
        "\n",
        "    print(\"Backtest completed. Portfolio metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "    return portfolio_values, weights_history, alpha_history, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzfqgvLMdihT"
      },
      "outputs": [],
      "source": [
        "def performancecomparison(results, data, train_end):\n",
        "    test_dates = data.index[train_end:train_end+len(results['dual_agent']['portfolio_values'])]\n",
        "\n",
        "    # Plot portfolio values\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.subplot(2, 1, 1)\n",
        "\n",
        "    for model_name, model_results in results.items():\n",
        "        plt.plot(test_dates, model_results['portfolio_values'], label=model_name)\n",
        "\n",
        "    # Add market regimes\n",
        "    if 'market_regime' in data.columns:\n",
        "        regime_changes = data.iloc[train_end:]['market_regime'].ne(\n",
        "            data.iloc[train_end:]['market_regime'].shift()\n",
        "        ).cumsum()\n",
        "        regime_groups = data.iloc[train_end:].groupby(regime_changes)\n",
        "\n",
        "        colors = ['red', 'yellow', 'green']\n",
        "        for _, group in regime_groups:\n",
        "            if len(group) > 0:\n",
        "                regime = group['market_regime'].iloc[0]\n",
        "                if pd.notna(regime) and regime < len(colors):\n",
        "                    plt.axvspan(group.index[0], group.index[-1], alpha=0.2,\n",
        "                              color=colors[int(regime)])\n",
        "\n",
        "    plt.title('Portfolio Value Comparison')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Portfolio Value')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot dual-agent risk budget\n",
        "    if 'dual_agent' in results and 'alphas' in results['dual_agent']:\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(test_dates[:-1], results['dual_agent']['alphas'], 'b-')\n",
        "        plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
        "        plt.title('Strategic Agent Risk Budget Allocation (α)')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Alpha')\n",
        "        plt.ylim(0, 1)\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('figures/performance_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot asset allocations\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for model_name, model_results in results.items():\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        plotasset(model_results['weights'], data.index[train_end:], model_name)\n",
        "        plt.savefig(f'figures/allocation_{model_name}.png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def plotasset(weights_history, dates, title):\n",
        "    weights_array = np.array(weights_history)\n",
        "\n",
        "    if len(dates) > len(weights_array):\n",
        "        dates = dates[:len(weights_array)]\n",
        "\n",
        "    n_assets = weights_array.shape[1]\n",
        "\n",
        "    # grouping similar assets\n",
        "    crypto_indices = list(range(n_assets-2, n_assets))\n",
        "    equity_indices = list(range(n_assets-2))\n",
        "\n",
        "    agg_weights = []\n",
        "    agg_labels = []\n",
        "\n",
        "    # Add crypto\n",
        "    for i in crypto_indices:\n",
        "        agg_weights.append(weights_array[:, i])\n",
        "        asset_name = \"BTC\" if i == n_assets-2 else \"ETH\"\n",
        "        agg_labels.append(asset_name)\n",
        "\n",
        "    # Group equities\n",
        "    tech_indices = list(range(0, min(10, len(equity_indices))))\n",
        "    finance_indices = list(range(10, min(20, len(equity_indices))))\n",
        "    other_indices = list(range(20, len(equity_indices)))\n",
        "\n",
        "    # Add sector groups\n",
        "    if tech_indices:\n",
        "        tech_weight = np.sum(weights_array[:, tech_indices], axis=1)\n",
        "        agg_weights.append(tech_weight)\n",
        "        agg_labels.append(\"Tech Stocks\")\n",
        "\n",
        "    if finance_indices:\n",
        "        finance_weight = np.sum(weights_array[:, finance_indices], axis=1)\n",
        "        agg_weights.append(finance_weight)\n",
        "        agg_labels.append(\"Finance Stocks\")\n",
        "\n",
        "    if other_indices:\n",
        "        other_weight = np.sum(weights_array[:, other_indices], axis=1)\n",
        "        agg_weights.append(other_weight)\n",
        "        agg_labels.append(\"Other Stocks\")\n",
        "\n",
        "    # Create stacked area plot\n",
        "    plt.stackplot(dates, agg_weights, labels=agg_labels, alpha=0.8)\n",
        "    plt.title(f'Asset Allocation - {title}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Weight')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "def plot_windowperformance(x_values, portfolio_values, alpha_history, weights_history, window_idx):\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Plot portfolio\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(x_values[:len(portfolio_values)], portfolio_values, 'b-')\n",
        "    plt.title(f'Portfolio Performance - Window {window_idx}')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Portfolio Value')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # risk budget allocation (alpha)\n",
        "    if len(alpha_history) > 0:\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(x_values[:len(alpha_history)], alpha_history, 'r-')\n",
        "        plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.5)\n",
        "        plt.title(f'Strategic Agent Risk Budget Allocation (α) - Window {window_idx}')\n",
        "        plt.xlabel('Time Step')\n",
        "        plt.ylabel('Alpha')\n",
        "        plt.ylim(0, 1)\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'figures/window_{window_idx}_performance.png')\n",
        "    plt.close()\n",
        "\n",
        "    # asset allocation\n",
        "    if len(weights_history) > 0:  # Check if we have weights\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        plotasset(weights_history, x_values[:len(weights_history)], f'Window {window_idx}')\n",
        "        plt.savefig(f'figures/window_{window_idx}_allocation.png')\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs3qHB8Stg3i"
      },
      "outputs": [],
      "source": [
        "def forward_validation(data, window_size=252, step_size=126, validation_size=126):\n",
        "    windows = []\n",
        "    data_length = len(data)\n",
        "\n",
        "    if window_size + validation_size > data_length:\n",
        "        raise ValueError(\"Not enough data for specified window and validation sizes\")\n",
        "\n",
        "    # Generate windows\n",
        "    start = 0\n",
        "    while start + window_size + validation_size <= data_length:\n",
        "        train_start = start\n",
        "        train_end = start + window_size\n",
        "        val_start = train_end\n",
        "        val_end = min(val_start + validation_size, data_length)\n",
        "\n",
        "        # Ensure windows\n",
        "        if val_end > val_start and train_end > train_start:\n",
        "            windows.append((train_start, train_end, val_start, val_end))\n",
        "\n",
        "        start += step_size\n",
        "\n",
        "    return windows\n",
        "\n",
        "def aggregate_window_results(results_dict):\n",
        "    all_metrics = [res['metrics'] for res in results_dict.values() if 'metrics' in res]\n",
        "    if not all_metrics:\n",
        "        return {}\n",
        "\n",
        "    sharpe_ratios = [m.get('sharpe', np.nan) for m in all_metrics]\n",
        "    returns = [m.get('return', np.nan) for m in all_metrics]\n",
        "    volatilities = [m.get('volatility', np.nan) for m in all_metrics]\n",
        "    drawdowns = [m.get('max_drawdown', np.nan) for m in all_metrics]\n",
        "    turnovers = [m.get('avg_turnover', np.nan) for m in all_metrics]\n",
        "    calmars = [m.get('calmar_ratio', np.nan) for m in all_metrics]\n",
        "\n",
        "    return {\n",
        "        \"windows\": len(all_metrics),\n",
        "        \"mean_sharpe\": np.nanmean(sharpe_ratios),\n",
        "        \"std_sharpe\": np.nanstd(sharpe_ratios),\n",
        "        \"mean_return\": np.nanmean(returns),\n",
        "        \"std_return\": np.nanstd(returns),\n",
        "        \"mean_volatility\": np.nanmean(volatilities),\n",
        "        \"mean_drawdown\": np.nanmean(drawdowns),\n",
        "        \"worst_drawdown\": np.nanmax(drawdowns),\n",
        "        \"mean_turnover\": np.nanmean(turnovers),\n",
        "        \"mean_calmar\": np.nanmean(calmars)\n",
        "    }\n",
        "\n",
        "def rollingwindow(data, selected_features, window_size=252, step_size=63, validation_size=63):\n",
        "\n",
        "    print(\"Implementing walk-forward validation...\")\n",
        "\n",
        "    # validation windows\n",
        "    windows = forward_validation(data, window_size, step_size, validation_size)\n",
        "    print(f\"Created {len(windows)} validation windows\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for window_idx, (train_start, train_end, val_start, val_end) in enumerate(windows):\n",
        "        print(f\"\\nProcessing window {window_idx+1}/{len(windows)}\")\n",
        "        print(f\"Training period: {train_start} to {train_end-1}\")\n",
        "        print(f\"Validation period: {val_start} to {val_end-1}\")\n",
        "\n",
        "        # max_steps\n",
        "        training_duration = train_end - train_start\n",
        "        lookback_window = min(30, training_duration // 3)\n",
        "        max_steps = max(1, training_duration - lookback_window)\n",
        "\n",
        "        # Create environment\n",
        "        env_kwargs = {\n",
        "            'data': data,\n",
        "            'selected_features': selected_features,\n",
        "            'window_size': lookback_window,\n",
        "            'train_period': (train_start, train_end),\n",
        "            'max_steps': max_steps,\n",
        "            'transaction_cost': 0.001,\n",
        "            'mode': 'train'\n",
        "        }\n",
        "\n",
        "        env = MultiMarketPortfolioEnv(**env_kwargs)\n",
        "\n",
        "        # dual-agent system\n",
        "        print(f\"Training dual-agent system for window {window_idx+1}...\")\n",
        "        dual_agent = DualAgentSystem(env)\n",
        "\n",
        "        training_steps = min(2000, window_size * 4)\n",
        "        dual_agent.train(total_timesteps=training_steps)\n",
        "\n",
        "        # Backtest\n",
        "        print(f\"Backtesting dual-agent system for window {window_idx+1}...\")\n",
        "        portfolio_values, weights_history, alpha_history, metrics = backtestportfolio(\n",
        "            dual_agent, data, val_start, val_end\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        try:\n",
        "            results[f'window_{window_idx+1}'] = {\n",
        "                'train_period': (train_start, train_end-1),\n",
        "                'val_period': (val_start, val_end-1),\n",
        "                'portfolio_values': portfolio_values,\n",
        "                'weights': weights_history,\n",
        "                'alphas': alpha_history,\n",
        "                'metrics': metrics\n",
        "            }\n",
        "\n",
        "            # Visualize\n",
        "            plot_windowperformance(\n",
        "                list(range(len(portfolio_values))),\n",
        "                portfolio_values,\n",
        "                alpha_history,\n",
        "                weights_history,\n",
        "                window_idx+1\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing results for window {window_idx+1}: {e}\")\n",
        "\n",
        "\n",
        "    # Aggregate results across all\n",
        "    try:\n",
        "        aggregate_results = aggregate_window_results(results)\n",
        "    except Exception as e:\n",
        "        print(f\"Error aggregating results: {e}\")\n",
        "        aggregate_results = {\"error\": str(e)}\n",
        "\n",
        "    return results, aggregate_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzrZjYuFhHar",
        "outputId": "f8050845-abb5-473c-9529-7a5afc74b7a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: shimmy in /home1/srajasek/.local/lib/python3.12/site-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from shimmy) (2.2.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /home1/srajasek/.local/lib/python3.12/site-packages (from shimmy) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/apps/conda/envs/ood-jupyterlab-4.2/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install shimmy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYoiU0Y_hSUm",
        "outputId": "838da47d-5001-44ce-a76e-0fea81fa358f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorboard in /home1/srajasek/.local/lib/python3.12/site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (2.2.2)\n",
            "Requirement already satisfied: packaging in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from tensorboard) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (6.30.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from tensorboard) (72.2.0)\n",
            "Requirement already satisfied: six>1.9 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home1/srajasek/.local/lib/python3.12/site-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /apps/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/apps/conda/envs/ood-jupyterlab-4.2/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYyq4PA4YrW2",
        "outputId": "717950a4-c103-4f89-a3a3-0d9b37d5f80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ROBVjdedk5Y",
        "outputId": "d3d69fe2-beaa-48be-9474-1ea691d69289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading preprocessed data...\n",
            "Data loaded with shape: (2580, 193)\n",
            "Enhancing features...\n",
            "Adding enhanced features...\n",
            "Processing features for 63 tickers\n",
            "Calculating technical indicators...\n",
            "Calculating RSI for KO\n",
            "Calculating RSI for AAPL\n",
            "Calculating RSI for ORCL\n",
            "Calculating RSI for VZ\n",
            "Calculating RSI for INTU\n",
            "Calculating RSI for NKE\n",
            "Calculating RSI for SBUX\n",
            "Calculating RSI for TSLA\n",
            "Calculating RSI for ABT\n",
            "Calculating RSI for RTX\n",
            "Calculating RSI for ACN\n",
            "Calculating RSI for DHR\n",
            "Calculating RSI for PM\n",
            "Calculating RSI for DIS\n",
            "Calculating RSI for HON\n",
            "Calculating RSI for MDT\n",
            "Calculating RSI for JPM\n",
            "Calculating RSI for ETH\n",
            "Calculating RSI for CRM\n",
            "Calculating RSI for BTC\n",
            "Calculating RSI for AMZN\n",
            "Calculating RSI for HD\n",
            "Calculating RSI for LOW\n",
            "Calculating RSI for MSFT\n",
            "Calculating RSI for TMO\n",
            "Calculating RSI for MRK\n",
            "Calculating RSI for META\n",
            "Calculating RSI for BRK-B\n",
            "Calculating RSI for PEP\n",
            "Calculating RSI for NEE\n",
            "Calculating RSI for NFLX\n",
            "Calculating RSI for CMCSA\n",
            "Calculating RSI for COST\n",
            "Calculating RSI for CVX\n",
            "Calculating RSI for BAC\n",
            "Calculating RSI for BMY\n",
            "Calculating RSI for GOOGL\n",
            "Calculating RSI for JNJ\n",
            "Calculating RSI for LLY\n",
            "Calculating RSI for CAT\n",
            "Calculating RSI for ABBV\n",
            "Calculating RSI for XOM\n",
            "Calculating RSI for WMT\n",
            "Calculating RSI for MCD\n",
            "Calculating RSI for AMD\n",
            "Calculating RSI for INTC\n",
            "Calculating RSI for MA\n",
            "Calculating RSI for PG\n",
            "Calculating RSI for AVGO\n",
            "Calculating RSI for ADBE\n",
            "Calculating RSI for IBM\n",
            "Calculating RSI for PFE\n",
            "Calculating RSI for COP\n",
            "Calculating RSI for GS\n",
            "Calculating RSI for SPY\n",
            "Calculating RSI for UNH\n",
            "Calculating RSI for CSCO\n",
            "Calculating RSI for NVDA\n",
            "Calculating RSI for TXN\n",
            "Calculating RSI for UNP\n",
            "Calculating RSI for AMGN\n",
            "Calculating RSI for V\n",
            "Calculating RSI for QCOM\n",
            "Calculating trend features for all tickers...\n",
            "Calculating moving averages for KO\n",
            "Calculating moving averages for AAPL\n",
            "Calculating moving averages for ORCL\n",
            "Calculating moving averages for VZ\n",
            "Calculating moving averages for INTU\n",
            "Calculating moving averages for NKE\n",
            "Calculating moving averages for SBUX\n",
            "Calculating moving averages for TSLA\n",
            "Calculating moving averages for ABT\n",
            "Calculating moving averages for RTX\n",
            "Calculating moving averages for ACN\n",
            "Calculating moving averages for DHR\n",
            "Calculating moving averages for PM\n",
            "Calculating moving averages for DIS\n",
            "Calculating moving averages for HON\n",
            "Calculating moving averages for MDT\n",
            "Calculating moving averages for JPM\n",
            "Calculating moving averages for ETH\n",
            "Calculating moving averages for CRM\n",
            "Calculating moving averages for BTC\n",
            "Calculating moving averages for AMZN\n",
            "Calculating moving averages for HD\n",
            "Calculating moving averages for LOW\n",
            "Calculating moving averages for MSFT\n",
            "Calculating moving averages for TMO\n",
            "Calculating moving averages for MRK\n",
            "Calculating moving averages for META\n",
            "Calculating moving averages for BRK-B\n",
            "Calculating moving averages for PEP\n",
            "Calculating moving averages for NEE\n",
            "Calculating moving averages for NFLX\n",
            "Calculating moving averages for CMCSA\n",
            "Calculating moving averages for COST\n",
            "Calculating moving averages for CVX\n",
            "Calculating moving averages for BAC\n",
            "Calculating moving averages for BMY\n",
            "Calculating moving averages for GOOGL\n",
            "Calculating moving averages for JNJ\n",
            "Calculating moving averages for LLY\n",
            "Calculating moving averages for CAT\n",
            "Calculating moving averages for ABBV\n",
            "Calculating moving averages for XOM\n",
            "Calculating moving averages for WMT\n",
            "Calculating moving averages for MCD\n",
            "Calculating moving averages for AMD\n",
            "Calculating moving averages for INTC\n",
            "Calculating moving averages for MA\n",
            "Calculating moving averages for PG\n",
            "Calculating moving averages for AVGO\n",
            "Calculating moving averages for ADBE\n",
            "Calculating moving averages for IBM\n",
            "Calculating moving averages for PFE\n",
            "Calculating moving averages for COP\n",
            "Calculating moving averages for GS\n",
            "Calculating moving averages for SPY\n",
            "Calculating moving averages for UNH\n",
            "Calculating moving averages for CSCO\n",
            "Calculating moving averages for NVDA\n",
            "Calculating moving averages for TXN\n",
            "Calculating moving averages for UNP\n",
            "Calculating moving averages for AMGN\n",
            "Calculating moving averages for V\n",
            "Calculating moving averages for QCOM\n",
            "Calculating cross-market correlations...\n",
            "Calculating sector-level features...\n",
            "Calculating market breadth indicators...\n",
            "Calculating volatility ratios...\n",
            "Detecting volatility regimes...\n",
            "NaN values after feature engineering: 9506\n",
            "Handling NaN values...\n",
            "NaN values after filling: 0\n",
            "Feature engineering complete.\n",
            "Enhanced data saved with shape: (2580, 585)\n",
            "Selecting features...\n",
            "Performing feature selection...\n",
            "Using 582 numeric features for selection\n",
            "Selected 219 features out of 582\n",
            "Selected 219 features\n",
            "Implementing walk-forward validation...\n",
            "Created 36 validation windows\n",
            "\n",
            "Processing window 1/36\n",
            "Training period: 0 to 251\n",
            "Validation period: 252 to 314\n",
            "Using max_steps=222 for training window 0:252\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Training dual-agent system for window 1...\n",
            "Using max_steps=222 for training window 0:252\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Using max_steps=222 for training window 0:252\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -354     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 122      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "Warning: Invalid random range (30 >= 30). Using fixed start index: 30\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 6.13     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 120      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 1...\n",
            "Backtesting from index 252 to 315\n",
            "Backtesting step 300/314\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0146\n",
            "annualized_return: -0.0579\n",
            "sharpe_ratio: -0.4072\n",
            "sortino_ratio: -0.4315\n",
            "max_drawdown: 0.0863\n",
            "calmar_ratio: -0.6710\n",
            "avg_turnover: 0.0805\n",
            "avg_strategic_allocation: 0.8000\n",
            "\n",
            "Processing window 2/36\n",
            "Training period: 63 to 314\n",
            "Validation period: 315 to 377\n",
            "Using max_steps=222 for training window 63:315\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Training dual-agent system for window 2...\n",
            "Using max_steps=222 for training window 63:315\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Using max_steps=222 for training window 63:315\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -301     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 122      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "Warning: Invalid random range (93 >= 93). Using fixed start index: 93\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -0.832   |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 120      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 2...\n",
            "Backtesting from index 315 to 378\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.1363\n",
            "annualized_return: -0.4486\n",
            "sharpe_ratio: -2.6000\n",
            "sortino_ratio: -2.9314\n",
            "max_drawdown: 0.1683\n",
            "calmar_ratio: -2.6663\n",
            "avg_turnover: 0.0740\n",
            "avg_strategic_allocation: 0.8000\n",
            "\n",
            "Processing window 3/36\n",
            "Training period: 126 to 377\n",
            "Validation period: 378 to 440\n",
            "Using max_steps=222 for training window 126:378\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Training dual-agent system for window 3...\n",
            "Using max_steps=222 for training window 126:378\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Using max_steps=222 for training window 126:378\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -438     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "Warning: Invalid random range (156 >= 156). Using fixed start index: 156\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -18.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 121      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 3...\n",
            "Backtesting from index 378 to 441\n",
            "Backtesting step 400/440\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.1788\n",
            "annualized_return: 0.9514\n",
            "sharpe_ratio: 3.8607\n",
            "sortino_ratio: 5.6848\n",
            "max_drawdown: 0.0282\n",
            "calmar_ratio: 33.7807\n",
            "avg_turnover: 0.0728\n",
            "avg_strategic_allocation: 0.8000\n",
            "\n",
            "Processing window 4/36\n",
            "Training period: 189 to 440\n",
            "Validation period: 441 to 503\n",
            "Using max_steps=222 for training window 189:441\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Training dual-agent system for window 4...\n",
            "Using max_steps=222 for training window 189:441\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Using max_steps=222 for training window 189:441\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -358     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "Warning: Invalid random range (219 >= 219). Using fixed start index: 219\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 17.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 4...\n",
            "Backtesting from index 441 to 504\n",
            "Backtesting step 500/503\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0327\n",
            "annualized_return: 0.1397\n",
            "sharpe_ratio: 1.6712\n",
            "sortino_ratio: 2.3592\n",
            "max_drawdown: 0.0223\n",
            "calmar_ratio: 6.2577\n",
            "avg_turnover: 0.0622\n",
            "avg_strategic_allocation: 0.7885\n",
            "\n",
            "Processing window 5/36\n",
            "Training period: 252 to 503\n",
            "Validation period: 504 to 566\n",
            "Using max_steps=222 for training window 252:504\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Training dual-agent system for window 5...\n",
            "Using max_steps=222 for training window 252:504\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Using max_steps=222 for training window 252:504\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -255     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "Warning: Invalid random range (282 >= 282). Using fixed start index: 282\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 20.8     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 5...\n",
            "Backtesting from index 504 to 567\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0514\n",
            "annualized_return: 0.2261\n",
            "sharpe_ratio: 1.9496\n",
            "sortino_ratio: 2.4808\n",
            "max_drawdown: 0.0478\n",
            "calmar_ratio: 4.7351\n",
            "avg_turnover: 0.0601\n",
            "avg_strategic_allocation: 0.7432\n",
            "\n",
            "Processing window 6/36\n",
            "Training period: 315 to 566\n",
            "Validation period: 567 to 629\n",
            "Using max_steps=222 for training window 315:567\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Training dual-agent system for window 6...\n",
            "Using max_steps=222 for training window 315:567\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Using max_steps=222 for training window 315:567\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -201     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "Warning: Invalid random range (345 >= 345). Using fixed start index: 345\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 69       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 6...\n",
            "Backtesting from index 567 to 630\n",
            "Backtesting step 600/629\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0318\n",
            "annualized_return: -0.1230\n",
            "sharpe_ratio: -0.8684\n",
            "sortino_ratio: -0.9710\n",
            "max_drawdown: 0.0784\n",
            "calmar_ratio: -1.5688\n",
            "avg_turnover: 0.0902\n",
            "avg_strategic_allocation: 0.7976\n",
            "\n",
            "Processing window 7/36\n",
            "Training period: 378 to 629\n",
            "Validation period: 630 to 692\n",
            "Using max_steps=222 for training window 378:630\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Training dual-agent system for window 7...\n",
            "Using max_steps=222 for training window 378:630\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Using max_steps=222 for training window 378:630\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -208     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "Warning: Invalid random range (408 >= 408). Using fixed start index: 408\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 42.9     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 7...\n",
            "Backtesting from index 630 to 693\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0231\n",
            "annualized_return: 0.0972\n",
            "sharpe_ratio: 0.9306\n",
            "sortino_ratio: 1.2082\n",
            "max_drawdown: 0.0657\n",
            "calmar_ratio: 1.4789\n",
            "avg_turnover: 0.0517\n",
            "avg_strategic_allocation: 0.7815\n",
            "\n",
            "Processing window 8/36\n",
            "Training period: 441 to 692\n",
            "Validation period: 693 to 755\n",
            "Using max_steps=222 for training window 441:693\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Training dual-agent system for window 8...\n",
            "Using max_steps=222 for training window 441:693\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Using max_steps=222 for training window 441:693\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -412     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "Warning: Invalid random range (471 >= 471). Using fixed start index: 471\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 11.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 8...\n",
            "Backtesting from index 693 to 756\n",
            "Backtesting step 700/755\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0024\n",
            "annualized_return: 0.0098\n",
            "sharpe_ratio: 0.1607\n",
            "sortino_ratio: 0.2612\n",
            "max_drawdown: 0.0419\n",
            "calmar_ratio: 0.2326\n",
            "avg_turnover: 0.0406\n",
            "avg_strategic_allocation: 0.7985\n",
            "\n",
            "Processing window 9/36\n",
            "Training period: 504 to 755\n",
            "Validation period: 756 to 818\n",
            "Using max_steps=222 for training window 504:756\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Training dual-agent system for window 9...\n",
            "Using max_steps=222 for training window 504:756\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Using max_steps=222 for training window 504:756\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -253     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "Warning: Invalid random range (534 >= 534). Using fixed start index: 534\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -7.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 9...\n",
            "Backtesting from index 756 to 819\n",
            "Backtesting step 800/818\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0699\n",
            "annualized_return: -0.2552\n",
            "sharpe_ratio: -1.2235\n",
            "sortino_ratio: -1.4777\n",
            "max_drawdown: 0.1283\n",
            "calmar_ratio: -1.9885\n",
            "avg_turnover: 0.0682\n",
            "avg_strategic_allocation: 0.8000\n",
            "\n",
            "Processing window 10/36\n",
            "Training period: 567 to 818\n",
            "Validation period: 819 to 881\n",
            "Using max_steps=222 for training window 567:819\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Training dual-agent system for window 10...\n",
            "Using max_steps=222 for training window 567:819\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Using max_steps=222 for training window 567:819\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -147     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "Warning: Invalid random range (597 >= 597). Using fixed start index: 597\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 20       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 10...\n",
            "Backtesting from index 819 to 882\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0254\n",
            "annualized_return: 0.1074\n",
            "sharpe_ratio: 0.4744\n",
            "sortino_ratio: 0.6037\n",
            "max_drawdown: 0.2380\n",
            "calmar_ratio: 0.4511\n",
            "avg_turnover: 0.0831\n",
            "avg_strategic_allocation: 0.7878\n",
            "\n",
            "Processing window 11/36\n",
            "Training period: 630 to 881\n",
            "Validation period: 882 to 944\n",
            "Using max_steps=222 for training window 630:882\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Training dual-agent system for window 11...\n",
            "Using max_steps=222 for training window 630:882\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Using max_steps=222 for training window 630:882\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -71.6    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "Warning: Invalid random range (660 >= 660). Using fixed start index: 660\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 11.8     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 121      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 11...\n",
            "Backtesting from index 882 to 945\n",
            "Backtesting step 900/944\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.1052\n",
            "annualized_return: 0.5015\n",
            "sharpe_ratio: 2.1836\n",
            "sortino_ratio: 2.1995\n",
            "max_drawdown: 0.0618\n",
            "calmar_ratio: 8.1184\n",
            "avg_turnover: 0.0634\n",
            "avg_strategic_allocation: 0.7643\n",
            "\n",
            "Processing window 12/36\n",
            "Training period: 693 to 944\n",
            "Validation period: 945 to 1007\n",
            "Using max_steps=222 for training window 693:945\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Training dual-agent system for window 12...\n",
            "Using max_steps=222 for training window 693:945\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Using max_steps=222 for training window 693:945\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -22.6    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "Warning: Invalid random range (723 >= 723). Using fixed start index: 723\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 14.5     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 12...\n",
            "Backtesting from index 945 to 1008\n",
            "Backtesting step 1000/1007\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0795\n",
            "annualized_return: 0.3649\n",
            "sharpe_ratio: 2.1641\n",
            "sortino_ratio: 2.1326\n",
            "max_drawdown: 0.0776\n",
            "calmar_ratio: 4.7017\n",
            "avg_turnover: 0.0765\n",
            "avg_strategic_allocation: 0.7693\n",
            "\n",
            "Processing window 13/36\n",
            "Training period: 756 to 1007\n",
            "Validation period: 1008 to 1070\n",
            "Using max_steps=222 for training window 756:1008\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Training dual-agent system for window 13...\n",
            "Using max_steps=222 for training window 756:1008\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Using max_steps=222 for training window 756:1008\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | 109      |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "Warning: Invalid random range (786 >= 786). Using fixed start index: 786\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 5.15     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 13...\n",
            "Backtesting from index 1008 to 1071\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0685\n",
            "annualized_return: 0.3092\n",
            "sharpe_ratio: 1.6421\n",
            "sortino_ratio: 2.3660\n",
            "max_drawdown: 0.0883\n",
            "calmar_ratio: 3.5015\n",
            "avg_turnover: 0.0737\n",
            "avg_strategic_allocation: 0.7800\n",
            "\n",
            "Processing window 14/36\n",
            "Training period: 819 to 1070\n",
            "Validation period: 1071 to 1133\n",
            "Using max_steps=222 for training window 819:1071\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Training dual-agent system for window 14...\n",
            "Using max_steps=222 for training window 819:1071\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Using max_steps=222 for training window 819:1071\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | 38.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "Warning: Invalid random range (849 >= 849). Using fixed start index: 849\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 98.7     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 14...\n",
            "Backtesting from index 1071 to 1134\n",
            "Backtesting step 1100/1133\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.1209\n",
            "annualized_return: 0.5901\n",
            "sharpe_ratio: 5.0440\n",
            "sortino_ratio: 8.4068\n",
            "max_drawdown: 0.0166\n",
            "calmar_ratio: 35.4740\n",
            "avg_turnover: 0.0561\n",
            "avg_strategic_allocation: 0.8000\n",
            "\n",
            "Processing window 15/36\n",
            "Training period: 882 to 1133\n",
            "Validation period: 1134 to 1196\n",
            "Using max_steps=222 for training window 882:1134\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Training dual-agent system for window 15...\n",
            "Using max_steps=222 for training window 882:1134\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Using max_steps=222 for training window 882:1134\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "Warning: Invalid random range (912 >= 912). Using fixed start index: 912\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 114      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 15...\n",
            "Backtesting from index 1134 to 1197\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0949\n",
            "annualized_return: 0.4454\n",
            "sharpe_ratio: 2.2513\n",
            "sortino_ratio: 3.0546\n",
            "max_drawdown: 0.0472\n",
            "calmar_ratio: 9.4414\n",
            "avg_turnover: 0.0917\n",
            "avg_strategic_allocation: 0.7750\n",
            "\n",
            "Processing window 16/36\n",
            "Training period: 945 to 1196\n",
            "Validation period: 1197 to 1259\n",
            "Using max_steps=222 for training window 945:1197\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Training dual-agent system for window 16...\n",
            "Using max_steps=222 for training window 945:1197\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Using max_steps=222 for training window 945:1197\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -43.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "Warning: Invalid random range (975 >= 975). Using fixed start index: 975\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 103      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 16...\n",
            "Backtesting from index 1197 to 1260\n",
            "Backtesting step 1200/1259\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0487\n",
            "annualized_return: 0.2134\n",
            "sharpe_ratio: 1.6916\n",
            "sortino_ratio: 2.5328\n",
            "max_drawdown: 0.0472\n",
            "calmar_ratio: 4.5178\n",
            "avg_turnover: 0.0720\n",
            "avg_strategic_allocation: 0.7316\n",
            "\n",
            "Processing window 17/36\n",
            "Training period: 1008 to 1259\n",
            "Validation period: 1260 to 1322\n",
            "Using max_steps=222 for training window 1008:1260\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Training dual-agent system for window 17...\n",
            "Using max_steps=222 for training window 1008:1260\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Using max_steps=222 for training window 1008:1260\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | 57.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "Warning: Invalid random range (1038 >= 1038). Using fixed start index: 1038\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 37.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 17...\n",
            "Backtesting from index 1260 to 1323\n",
            "Backtesting step 1300/1322\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0568\n",
            "annualized_return: 0.2516\n",
            "sharpe_ratio: 1.5123\n",
            "sortino_ratio: 2.6702\n",
            "max_drawdown: 0.0498\n",
            "calmar_ratio: 5.0545\n",
            "avg_turnover: 0.0700\n",
            "avg_strategic_allocation: 0.7538\n",
            "\n",
            "Processing window 18/36\n",
            "Training period: 1071 to 1322\n",
            "Validation period: 1323 to 1385\n",
            "Using max_steps=222 for training window 1071:1323\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Training dual-agent system for window 18...\n",
            "Using max_steps=222 for training window 1071:1323\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Using max_steps=222 for training window 1071:1323\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -147     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "Warning: Invalid random range (1101 >= 1101). Using fixed start index: 1101\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 26       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 18...\n",
            "Backtesting from index 1323 to 1386\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0828\n",
            "annualized_return: 0.3820\n",
            "sharpe_ratio: 2.0863\n",
            "sortino_ratio: 2.8557\n",
            "max_drawdown: 0.0871\n",
            "calmar_ratio: 4.3856\n",
            "avg_turnover: 0.0778\n",
            "avg_strategic_allocation: 0.7605\n",
            "\n",
            "Processing window 19/36\n",
            "Training period: 1134 to 1385\n",
            "Validation period: 1386 to 1448\n",
            "Using max_steps=222 for training window 1134:1386\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Training dual-agent system for window 19...\n",
            "Using max_steps=222 for training window 1134:1386\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Using max_steps=222 for training window 1134:1386\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -216     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "Warning: Invalid random range (1164 >= 1164). Using fixed start index: 1164\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 20.7     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 19...\n",
            "Backtesting from index 1386 to 1449\n",
            "Backtesting step 1400/1448\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0972\n",
            "annualized_return: 0.4577\n",
            "sharpe_ratio: 2.6921\n",
            "sortino_ratio: 4.5356\n",
            "max_drawdown: 0.0314\n",
            "calmar_ratio: 14.5918\n",
            "avg_turnover: 0.0773\n",
            "avg_strategic_allocation: 0.7101\n",
            "\n",
            "Processing window 20/36\n",
            "Training period: 1197 to 1448\n",
            "Validation period: 1449 to 1511\n",
            "Using max_steps=222 for training window 1197:1449\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Training dual-agent system for window 20...\n",
            "Using max_steps=222 for training window 1197:1449\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Using max_steps=222 for training window 1197:1449\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -233     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "Warning: Invalid random range (1227 >= 1227). Using fixed start index: 1227\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 52.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 20...\n",
            "Backtesting from index 1449 to 1512\n",
            "Backtesting step 1500/1511\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0829\n",
            "annualized_return: -0.2966\n",
            "sharpe_ratio: -2.3129\n",
            "sortino_ratio: -2.9441\n",
            "max_drawdown: 0.1214\n",
            "calmar_ratio: -2.4434\n",
            "avg_turnover: 0.0853\n",
            "avg_strategic_allocation: 0.6066\n",
            "\n",
            "Processing window 21/36\n",
            "Training period: 1260 to 1511\n",
            "Validation period: 1512 to 1574\n",
            "Using max_steps=222 for training window 1260:1512\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Training dual-agent system for window 21...\n",
            "Using max_steps=222 for training window 1260:1512\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Using max_steps=222 for training window 1260:1512\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -315     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "Warning: Invalid random range (1290 >= 1290). Using fixed start index: 1290\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 41.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 21...\n",
            "Backtesting from index 1512 to 1575\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0653\n",
            "annualized_return: 0.2934\n",
            "sharpe_ratio: 1.5141\n",
            "sortino_ratio: 2.3987\n",
            "max_drawdown: 0.0662\n",
            "calmar_ratio: 4.4319\n",
            "avg_turnover: 0.0871\n",
            "avg_strategic_allocation: 0.7866\n",
            "\n",
            "Processing window 22/36\n",
            "Training period: 1323 to 1574\n",
            "Validation period: 1575 to 1637\n",
            "Using max_steps=222 for training window 1323:1575\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Training dual-agent system for window 22...\n",
            "Using max_steps=222 for training window 1323:1575\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Using max_steps=222 for training window 1323:1575\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -369     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "Warning: Invalid random range (1353 >= 1353). Using fixed start index: 1353\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 32.4     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 22...\n",
            "Backtesting from index 1575 to 1638\n",
            "Backtesting step 1600/1637\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0681\n",
            "annualized_return: -0.2492\n",
            "sharpe_ratio: -1.1957\n",
            "sortino_ratio: -1.4091\n",
            "max_drawdown: 0.1307\n",
            "calmar_ratio: -1.9066\n",
            "avg_turnover: 0.0474\n",
            "avg_strategic_allocation: 0.7848\n",
            "\n",
            "Processing window 23/36\n",
            "Training period: 1386 to 1637\n",
            "Validation period: 1638 to 1700\n",
            "Using max_steps=222 for training window 1386:1638\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Training dual-agent system for window 23...\n",
            "Using max_steps=222 for training window 1386:1638\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Using max_steps=222 for training window 1386:1638\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -520     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "Warning: Invalid random range (1416 >= 1416). Using fixed start index: 1416\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -0.189   |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 23...\n",
            "Backtesting from index 1638 to 1701\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0197\n",
            "annualized_return: -0.0778\n",
            "sharpe_ratio: -0.1571\n",
            "sortino_ratio: -0.2072\n",
            "max_drawdown: 0.1879\n",
            "calmar_ratio: -0.4140\n",
            "avg_turnover: 0.0709\n",
            "avg_strategic_allocation: 0.7649\n",
            "\n",
            "Processing window 24/36\n",
            "Training period: 1449 to 1700\n",
            "Validation period: 1701 to 1763\n",
            "Using max_steps=222 for training window 1449:1701\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Training dual-agent system for window 24...\n",
            "Using max_steps=222 for training window 1449:1701\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Using max_steps=222 for training window 1449:1701\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -476     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "Warning: Invalid random range (1479 >= 1479). Using fixed start index: 1479\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -9.76    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 24...\n",
            "Backtesting from index 1701 to 1764\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.1090\n",
            "annualized_return: -0.3744\n",
            "sharpe_ratio: -2.1255\n",
            "sortino_ratio: -2.5758\n",
            "max_drawdown: 0.1600\n",
            "calmar_ratio: -2.3397\n",
            "avg_turnover: 0.0697\n",
            "avg_strategic_allocation: 0.7845\n",
            "\n",
            "Processing window 25/36\n",
            "Training period: 1512 to 1763\n",
            "Validation period: 1764 to 1826\n",
            "Using max_steps=222 for training window 1512:1764\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Training dual-agent system for window 25...\n",
            "Using max_steps=222 for training window 1512:1764\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Using max_steps=222 for training window 1512:1764\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -435     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "Warning: Invalid random range (1542 >= 1542). Using fixed start index: 1542\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -28.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 25...\n",
            "Backtesting from index 1764 to 1827\n",
            "Backtesting step 1800/1826\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0625\n",
            "annualized_return: 0.2795\n",
            "sharpe_ratio: 1.2035\n",
            "sortino_ratio: 2.2653\n",
            "max_drawdown: 0.0622\n",
            "calmar_ratio: 4.4945\n",
            "avg_turnover: 0.0669\n",
            "avg_strategic_allocation: 0.7579\n",
            "\n",
            "Processing window 26/36\n",
            "Training period: 1575 to 1826\n",
            "Validation period: 1827 to 1889\n",
            "Using max_steps=222 for training window 1575:1827\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Training dual-agent system for window 26...\n",
            "Using max_steps=222 for training window 1575:1827\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Using max_steps=222 for training window 1575:1827\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -236     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "Warning: Invalid random range (1605 >= 1605). Using fixed start index: 1605\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -25.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 26...\n",
            "Backtesting from index 1827 to 1890\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0489\n",
            "annualized_return: 0.2141\n",
            "sharpe_ratio: 1.3118\n",
            "sortino_ratio: 1.9049\n",
            "max_drawdown: 0.0664\n",
            "calmar_ratio: 3.2242\n",
            "avg_turnover: 0.0998\n",
            "avg_strategic_allocation: 0.7773\n",
            "\n",
            "Processing window 27/36\n",
            "Training period: 1638 to 1889\n",
            "Validation period: 1890 to 1952\n",
            "Using max_steps=222 for training window 1638:1890\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Training dual-agent system for window 27...\n",
            "Using max_steps=222 for training window 1638:1890\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Using max_steps=222 for training window 1638:1890\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -230     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "Warning: Invalid random range (1668 >= 1668). Using fixed start index: 1668\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -17.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 27...\n",
            "Backtesting from index 1890 to 1953\n",
            "Backtesting step 1900/1952\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0246\n",
            "annualized_return: 0.1040\n",
            "sharpe_ratio: 0.7969\n",
            "sortino_ratio: 1.0630\n",
            "max_drawdown: 0.0772\n",
            "calmar_ratio: 1.3458\n",
            "avg_turnover: 0.0890\n",
            "avg_strategic_allocation: 0.7992\n",
            "\n",
            "Processing window 28/36\n",
            "Training period: 1701 to 1952\n",
            "Validation period: 1953 to 2015\n",
            "Using max_steps=222 for training window 1701:1953\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Training dual-agent system for window 28...\n",
            "Using max_steps=222 for training window 1701:1953\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Using max_steps=222 for training window 1701:1953\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -236     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "Warning: Invalid random range (1731 >= 1731). Using fixed start index: 1731\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -4.62    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 28...\n",
            "Backtesting from index 1953 to 2016\n",
            "Backtesting step 2000/2015\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0766\n",
            "annualized_return: 0.3496\n",
            "sharpe_ratio: 2.9135\n",
            "sortino_ratio: 5.4257\n",
            "max_drawdown: 0.0266\n",
            "calmar_ratio: 13.1574\n",
            "avg_turnover: 0.0407\n",
            "avg_strategic_allocation: 0.7517\n",
            "\n",
            "Processing window 29/36\n",
            "Training period: 1764 to 2015\n",
            "Validation period: 2016 to 2078\n",
            "Using max_steps=222 for training window 1764:2016\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Training dual-agent system for window 29...\n",
            "Using max_steps=222 for training window 1764:2016\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Using max_steps=222 for training window 1764:2016\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -289     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "Warning: Invalid random range (1794 >= 1794). Using fixed start index: 1794\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -12      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 29...\n",
            "Backtesting from index 2016 to 2079\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0150\n",
            "annualized_return: 0.0623\n",
            "sharpe_ratio: 0.8398\n",
            "sortino_ratio: 1.2278\n",
            "max_drawdown: 0.0250\n",
            "calmar_ratio: 2.4902\n",
            "avg_turnover: 0.0624\n",
            "avg_strategic_allocation: 0.7356\n",
            "\n",
            "Processing window 30/36\n",
            "Training period: 1827 to 2078\n",
            "Validation period: 2079 to 2141\n",
            "Using max_steps=222 for training window 1827:2079\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Training dual-agent system for window 30...\n",
            "Using max_steps=222 for training window 1827:2079\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Using max_steps=222 for training window 1827:2079\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -280     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "Warning: Invalid random range (1857 >= 1857). Using fixed start index: 1857\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -31.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 30...\n",
            "Backtesting from index 2079 to 2142\n",
            "Backtesting step 2100/2141\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0340\n",
            "annualized_return: -0.1311\n",
            "sharpe_ratio: -1.3397\n",
            "sortino_ratio: -2.0272\n",
            "max_drawdown: 0.0634\n",
            "calmar_ratio: -2.0672\n",
            "avg_turnover: 0.1110\n",
            "avg_strategic_allocation: 0.5452\n",
            "\n",
            "Processing window 31/36\n",
            "Training period: 1890 to 2141\n",
            "Validation period: 2142 to 2204\n",
            "Using max_steps=222 for training window 1890:2142\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Training dual-agent system for window 31...\n",
            "Using max_steps=222 for training window 1890:2142\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Using max_steps=222 for training window 1890:2142\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -495     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "Warning: Invalid random range (1920 >= 1920). Using fixed start index: 1920\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -26.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 31...\n",
            "Backtesting from index 2142 to 2205\n",
            "Backtesting step 2200/2204\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.1587\n",
            "annualized_return: 0.8196\n",
            "sharpe_ratio: 5.4585\n",
            "sortino_ratio: 7.3539\n",
            "max_drawdown: 0.0277\n",
            "calmar_ratio: 29.6010\n",
            "avg_turnover: 0.0634\n",
            "avg_strategic_allocation: 0.7396\n",
            "\n",
            "Processing window 32/36\n",
            "Training period: 1953 to 2204\n",
            "Validation period: 2205 to 2267\n",
            "Using max_steps=222 for training window 1953:2205\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Training dual-agent system for window 32...\n",
            "Using max_steps=222 for training window 1953:2205\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Using max_steps=222 for training window 1953:2205\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -387     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "Warning: Invalid random range (1983 >= 1983). Using fixed start index: 1983\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 41       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 32...\n",
            "Backtesting from index 2205 to 2268\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.1212\n",
            "annualized_return: 0.5917\n",
            "sharpe_ratio: 3.9859\n",
            "sortino_ratio: 7.5452\n",
            "max_drawdown: 0.0197\n",
            "calmar_ratio: 30.0446\n",
            "avg_turnover: 0.0672\n",
            "avg_strategic_allocation: 0.7862\n",
            "\n",
            "Processing window 33/36\n",
            "Training period: 2016 to 2267\n",
            "Validation period: 2268 to 2330\n",
            "Using max_steps=222 for training window 2016:2268\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Training dual-agent system for window 33...\n",
            "Using max_steps=222 for training window 2016:2268\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Using max_steps=222 for training window 2016:2268\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -382     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "Warning: Invalid random range (2046 >= 2046). Using fixed start index: 2046\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 16.5     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 33...\n",
            "Backtesting from index 2268 to 2331\n",
            "Backtesting step 2300/2330\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: -0.0235\n",
            "annualized_return: -0.0921\n",
            "sharpe_ratio: -0.9827\n",
            "sortino_ratio: -1.2605\n",
            "max_drawdown: 0.0638\n",
            "calmar_ratio: -1.4442\n",
            "avg_turnover: 0.0435\n",
            "avg_strategic_allocation: 0.7027\n",
            "\n",
            "Processing window 34/36\n",
            "Training period: 2079 to 2330\n",
            "Validation period: 2331 to 2393\n",
            "Using max_steps=222 for training window 2079:2331\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Training dual-agent system for window 34...\n",
            "Using max_steps=222 for training window 2079:2331\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Using max_steps=222 for training window 2079:2331\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -159     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "Warning: Invalid random range (2109 >= 2109). Using fixed start index: 2109\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 25.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 34...\n",
            "Backtesting from index 2331 to 2394\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0361\n",
            "annualized_return: 0.1551\n",
            "sharpe_ratio: 1.7317\n",
            "sortino_ratio: 2.1921\n",
            "max_drawdown: 0.0412\n",
            "calmar_ratio: 3.7690\n",
            "avg_turnover: 0.0442\n",
            "avg_strategic_allocation: 0.7993\n",
            "\n",
            "Processing window 35/36\n",
            "Training period: 2142 to 2393\n",
            "Validation period: 2394 to 2456\n",
            "Using max_steps=222 for training window 2142:2394\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Training dual-agent system for window 35...\n",
            "Using max_steps=222 for training window 2142:2394\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Using max_steps=222 for training window 2142:2394\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -296     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "Warning: Invalid random range (2172 >= 2172). Using fixed start index: 2172\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 35.7     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 35...\n",
            "Backtesting from index 2394 to 2457\n",
            "Backtesting step 2400/2456\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0296\n",
            "annualized_return: 0.1258\n",
            "sharpe_ratio: 1.1620\n",
            "sortino_ratio: 1.3752\n",
            "max_drawdown: 0.0618\n",
            "calmar_ratio: 2.0362\n",
            "avg_turnover: 0.0581\n",
            "avg_strategic_allocation: 0.7134\n",
            "\n",
            "Processing window 36/36\n",
            "Training period: 2205 to 2456\n",
            "Validation period: 2457 to 2519\n",
            "Using max_steps=222 for training window 2205:2457\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Training dual-agent system for window 36...\n",
            "Using max_steps=222 for training window 2205:2457\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Using max_steps=222 for training window 2205:2457\n",
            "Environment created with 63 assets\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Training strategic agent...\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | -432     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Training tactical agent (DQN)...\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "Warning: Invalid random range (2235 >= 2235). Using fixed start index: 2235\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 58.8     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 7        |\n",
            "|    time_elapsed     | 125      |\n",
            "|    total_timesteps  | 888      |\n",
            "----------------------------------\n",
            "Backtesting dual-agent system for window 36...\n",
            "Backtesting from index 2457 to 2520\n",
            "Backtesting step 2500/2519\n",
            "Backtest completed. Portfolio metrics:\n",
            "total_return: 0.0226\n",
            "annualized_return: 0.0951\n",
            "sharpe_ratio: 0.8935\n",
            "sortino_ratio: 1.2165\n",
            "max_drawdown: 0.0430\n",
            "calmar_ratio: 2.2132\n",
            "avg_turnover: 0.0654\n",
            "avg_strategic_allocation: 0.6881\n",
            "\n",
            "Aggregate Performance Metrics:\n",
            "Number of windows: 36\n",
            "Mean Sharpe ratio: nan ± nan\n",
            "Mean return: nan ± nan\n",
            "Mean max drawdown: 0.0738\n",
            "Worst drawdown: 0.2380\n",
            "Mean Calmar ratio: 6.0006\n",
            "Saving results...\n",
            "Implementation complete!\n"
          ]
        }
      ],
      "source": [
        "# the preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "try:\n",
        "    aligned_data = pd.read_csv('/scratch1/srajasek/DL_f/clean_full_data.csv')\n",
        "    print(f\"Data loaded with shape: {aligned_data.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "\n",
        "\n",
        "# Enhance features\n",
        "print(\"Enhancing features...\")\n",
        "enhanced_data = efeatures(aligned_data)\n",
        "enhanced_data.to_csv('/scratch1/srajasek/DL_f/data/enhanced_multimarket_data.csv')\n",
        "print(f\"Enhanced data saved with shape: {enhanced_data.shape}\")\n",
        "\n",
        "# Feature selection\n",
        "print(\"Selecting features...\")\n",
        "selected_features = sfeatures(enhanced_data)\n",
        "print(f\"Selected {len(selected_features)} features\")\n",
        "\n",
        "# Implement walk-forward validation\n",
        "window_size = 252\n",
        "step_size = 63\n",
        "validation_size = 63\n",
        "\n",
        "window_results, aggregate_results = rollingwindow(\n",
        "    enhanced_data,\n",
        "    selected_features,\n",
        "    window_size,\n",
        "    step_size,\n",
        "    validation_size\n",
        ")\n",
        "\n",
        "# Print aggregate\n",
        "print(\"\\nAggregate Performance Metrics:\")\n",
        "print(f\"Number of windows: {aggregate_results['windows']}\")\n",
        "print(f\"Mean Sharpe ratio: {aggregate_results['mean_sharpe']:.4f} ± {aggregate_results['std_sharpe']:.4f}\")\n",
        "print(f\"Mean return: {aggregate_results['mean_return']:.4f} ± {aggregate_results['std_return']:.4f}\")\n",
        "print(f\"Mean max drawdown: {aggregate_results['mean_drawdown']:.4f}\")\n",
        "print(f\"Worst drawdown: {aggregate_results['worst_drawdown']:.4f}\")\n",
        "print(f\"Mean Calmar ratio: {aggregate_results['mean_calmar']:.4f}\")\n",
        "\n",
        "# Save results\n",
        "print(\"Saving results...\")\n",
        "import pickle\n",
        "with open('results/rolling_window_results.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'window_results': window_results,\n",
        "        'aggregate_results': aggregate_results\n",
        "    }, f)\n",
        "\n",
        "print(\"Implementation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load saved results\n",
        "with open('/content/rolling_window_results.pkl', 'rb') as f:\n",
        "    saved_data = pickle.load(f)\n",
        "\n",
        "window_results = saved_data['window_results']\n",
        "\n",
        "# Initialize metric lists\n",
        "sharpe_ratios = []\n",
        "returns = []\n",
        "drawdowns = []\n",
        "calmars = []\n",
        "\n",
        "# Extract metrics\n",
        "for window_id, result in window_results.items():\n",
        "    metrics = result.get(\"metrics\", {})\n",
        "    sharpe = metrics.get(\"sharpe_ratio\", np.nan)\n",
        "    ret = metrics.get(\"annualized_return\", np.nan)\n",
        "    drawdown = metrics.get(\"max_drawdown\", np.nan)\n",
        "    calmar = metrics.get(\"calmar_ratio\", np.nan)\n",
        "\n",
        "    if not np.isnan(sharpe): sharpe_ratios.append(sharpe)\n",
        "    if not np.isnan(ret): returns.append(ret)\n",
        "    if not np.isnan(drawdown): drawdowns.append(drawdown)\n",
        "    if not np.isnan(calmar): calmars.append(calmar)\n",
        "\n",
        "# Compute aggregate\n",
        "aggregate_metrics = {\n",
        "    \"windows\": len(sharpe_ratios),\n",
        "    \"mean_sharpe\": np.mean(sharpe_ratios) if sharpe_ratios else np.nan,\n",
        "    \"std_sharpe\": np.std(sharpe_ratios) if sharpe_ratios else np.nan,\n",
        "    \"mean_return\": np.mean(returns) if returns else np.nan,\n",
        "    \"std_return\": np.std(returns) if returns else np.nan,\n",
        "    \"mean_drawdown\": np.mean(drawdowns) if drawdowns else np.nan,\n",
        "    \"worst_drawdown\": np.max(drawdowns) if drawdowns else np.nan,\n",
        "    \"mean_calmar\": np.mean(calmars) if calmars else np.nan,\n",
        "}\n",
        "\n",
        "print(\"\\n Aggregate Performance Metrics:\")\n",
        "print(f\"Number of valid windows: {aggregate_metrics['windows']}\")\n",
        "print(f\"Mean Sharpe ratio: {aggregate_metrics['mean_sharpe']:.4f} ± {aggregate_metrics['std_sharpe']:.4f}\")\n",
        "print(f\"Mean return: {aggregate_metrics['mean_return']:.4f} ± {aggregate_metrics['std_return']:.4f}\")\n",
        "print(f\"Mean max drawdown: {aggregate_metrics['mean_drawdown']:.4f}\")\n",
        "print(f\"Worst drawdown: {aggregate_metrics['worst_drawdown']:.4f}\")\n",
        "print(f\"Mean Calmar ratio: {aggregate_metrics['mean_calmar']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjBwzMU_wwTQ",
        "outputId": "31226bb6-db6f-4efb-c4c7-c863f82e6db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Aggregate Performance Metrics:\n",
            "Number of valid windows: 36\n",
            "Mean Sharpe ratio: 1.0809 ± 1.8955\n",
            "Mean return: 0.1676 ± 0.3119\n",
            "Mean max drawdown: 0.0738\n",
            "Worst drawdown: 0.2380\n",
            "Mean Calmar ratio: 6.0006\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.5 (default)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}